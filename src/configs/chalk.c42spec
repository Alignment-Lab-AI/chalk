## This is the con4m specification to enable con4m to automatically
## validate chalk config files.
##
## :Author: John Viega (john@crashoverride.com)
## :Copyright: 2023, Crash Override, Inc.


default_key_priority := 4611686018427387904  # 2^62.

# These are the valid command-line commands.
valid_chalk_cmds     := ["help", "insert", "extract", "delete", "defaults",
		         #% REWRITE ,$ ]
                         "load", "dump", "docker", "version",
			 #% INTERNAL
			 "entrypoint"]
			 #% END
all_cmds_that_insert := ["insert", "build", "load"]

# These will all either be command names, or will set by the
# appropriate plugin.  Eg., the docker plugin only reports 'docker' if
# it does nothing except pass through the docker command due to the
# docker verb being unwrapped.  On a 'docker build', the report op is 'build'
# and on a 'docker push' the report op is 'push'.
#
# This value isn't actually checked; the runtime is trusted to get the correct.
#
# valid_report_ops   := valid_chalk_cmds + ["build", "push"]


tool_types           := ["sbom", "sast"]
valid_log_levels     := ["verbose", "trace", "info", "warn", "error", "none"]
key_types            := ["Chalkable Host", "Chalk", "Non-Chalk", "Host Only"]
known_sink_filters   := ["log_level", "log_prefix", "pretty_json",
                         "fix_new_line", "add_topic", "wrap"]

# This is the enum for key types.   See 'key' object documentation below
# for more details.
#
enum ChalkableHost, Chalk, NonChalk, HostOnly

## Collection contexts
# The four times plugins may choose to collect metadata:
# 1) Pre-run:       Things we collect before we start processing artifacts.
#                   Generally host level-info, that we stuff into artifacts.
#                   This could include things that *might* be different on
#                   a per-artifact basis, but where our collection isn't yet
#                   good enough.
#
# 2) Artifact:      While we are processing artifacts (insertion or
#                   extraction).  This *can* include non-chalkable keys.

# 3) Post-Artifact: Stuff we collect after the artifact is written,
#                   including at collection time.  This *cannot* include
#                   non-chalkable keys.

# 4) Post-Run:      Stuff we collect after we're done processing any
#                   artifacts. Ususally expect this to be stats, etc.
#                   Nothing here can be chalkable.
# These are just used internally as part of validation routines.
enum CCPreRun, CCArtifact, CCPostChalk, CCPostRun
enum PTChalk, PTArtifact, PTHost, PTChalkTimeArtifact

# Make these available through stacks.  Enums are automatically
# avalable through stacks.
export default_key_priority, valid_chalk_cmds, all_cmds_that_insert
export known_sink_filters

object key {
  # TODO: no callbacks or value fields when system is set on the keyspec.
  user_def_ok:   false
  gen_fieldname: "keys"
  gen_typename:  "KeyConfig"
  gen_setters:   false
  doc:           """
Specifies profile-specific properties for specific metadata keys.
Currently, there is only a 'report' field.

See 'chalk help keyspec' for an overview of how keys are specified,
'chalk help keys' for lists of metadata keys, or 'chalk help key KEYNAME'
for all information on a single key.
"""

  field report {
    type:     bool
    default:  true
    doc: """
Whether to include the specific key when the profile reports.

Note that, when you explicitly enable keys in a profile, any reporting
context using the profile must be valid for the keys set to 'report',
or else you will get an error.
"""
  }

  field order {
    type:     int
    require:  false
    doc:      """
Used to set the reporting order. If not provided, this will inherit
the normalization order from the associated keyspec.
"""
  }
}

object profile {
  user_def_ok:   false
  gen_fieldname: "profiles"
  gen_typename:  "Profile"
  gen_setters:   false

  field enabled {
    type:    bool
    default: true
    doc: """
Whether to use this profile. If it's disabled, it won't be used, even
if it's part of the current 'outspec'.  If a command can't report at
all (or can't chalk if an insert command), then chalk will not run.
"""
  }

  field doc {
    type:     string
    require:  false
    hidden:   true
  }

  allow key {}
  doc: """
Profiles are part of how you can customize what metadata goes
where.

On insert operations, there's a profile that governs what goes into
chalk marks.

For each command to chalk, there will be at least two profiles
that govern the command, a host-level reporting profile, and an
artifact-level reporting profile. These reports are discussed in the
documentation for the 'outconf' section type, as is configuring output
sinks for reporting.

You can also set up custom reports that output whatever metadata you
like in addition to the 'standard' reporting.
"""
}

object tool {
   user_def_ok:   true
   gen_fieldname: "tools"
   gen_typename:  "ToolInfo"
   gen_setters:   false
   doc:           """

Tool sections allow you to automatically run external tools for
collecting metadata, for tool types that are known to chalk (This
doesn't preclude chalk from providing its own collection for these
keys in the future).

Some of these tools are pre-configured with chalk, but you can also
add your own tool sections, as long as you provide appropriate
information in the config file via con4m callbacks.

Current tool classes are "sbom" and "sast":

- "sbom" tools collect SBOM information on a per-artifact basis.
- "sast" tools perform static analysis, and give a SARIF-formatted output.

You can run multiple tools of the same kind. Each tool metadata key
returns a key-value pair, the keys representing tools as named in the
configuration file, and the value being the output in string format:

- SBOMs are expected be returned in CycloneDX format. The appropriate
        metadata key these will be reported through, is 'SBOM'.
- SAST output is expected to be returned in the SARIF format.

Note that chalk itself is not currently validating the format, but the
tools that ship with chalk (see "chalk defaults tools") currently
respect it (with appropriate escaping to marshal them into a JSON
string).

Additionally, it is possible to use external code-signing tools. By
default, chalk will use gpg if present, signing if the GPG_SIGNING_KEY
variable is set.  However, this is implemented via a con4m callback
that you may override.  This is not configured as part of 'tool'
sections.
"""
   field enabled {
     type:     bool
     default:  true
     doc:      "If this is set to false, the tool is never run."
   }

   field kind {
     type:       string
     require:    true
     choice:     tool_types
     write_lock: true
     doc:        "Specifies which kind of tool this is."
   }

   field runs_once {
     type:       bool
     default:    true
     write_lock: true
     doc:        "Does the tool implementation get invoked per-artifact or per-run?"
   }

   field priority {
     type:     int
     default:  50
     range:    (0, high())
     doc:      """
Prioritizes the order tools get called in. Lower numbers are higher priorities.
"""
   }

   field stop_on_success {
     type:     bool
     default:  false
     doc:      "Use this if you only want to run one tool, but want to " +
               "try a number of tools until one is found.  Specifically, " +
	       "If a tool sets this and runs successfully, no tool of the " +
	       "same kind that has a lower priority will run at all."
   }

   field get_tool_location {
     type:     func (string) -> string
     require:  true
     doc:      """
A callback used when implementing tools. This must return the path to
the tool, after searching for it.  The argument will pass any
operation-specific context if a tool might be called with different
contexts that might require different actual tools.  Specifically, the
path will be passed for all existing tool types.

There is a generic implementation of this called `do_which` that can
be used directly, or can be called if you want to do something fancier.
"""

   }

   field attempt_install {
     type:     func (string) -> bool
     require:  true
     doc:      """

A callback used when implementing tools.  You must implement this for
any new tool you add, even if you have no intention of ever attempting
an actual installation (in which case, it can simply return false).
get_tool_location() will be called again if the install is reported
to be successful.

See the con4m documentation for functions that can help, such as file
access, execution, etc.
"""
   }

   field get_command_args {
     type:     func (string) -> string
     require:  true
     doc:      """
Given the artifact path and an argument determined based on the
metadata-key, return the command-line (argv minus program name) that
we should run. This is passed to the system shell; Note that we do not
run w/ privs even if chalk is setuid()
"""
   }

   field produce_keys {
     # exit code, output
     type:     func (string, int) -> dict[string, string]
     require:  true
     doc:      """
Given the exit code and output from running the command line, return
the appropriate value.  You're expected to return the chalk key name
from the keyspec object, and the value.  For instance, when
implementing an SBOM tool, return {"SBOM" : "..."}, even though this
will get lifted to {"SBOM" : {"yourtool" : "..."}} once multiple tools
are processed.

Note that if tool execution fails, or there is no output, you can
return no value.  If you want to output an error, warning, or
informational statement, you can add the key "error", "warn", or
"info" (must be lower case to distinguish from metadata keys).

If the "error" key is present, this will also be taken as a tool
failure, and no other keys will be checked.
"""
   }

  field doc {
    type:     string
    require:  false
    hidden:   true
  }
}

object keyspec {
  user_def_ok:   false
  gen_fieldname: "keyspecs"
  gen_typename:  "KeySpec"
  gen_setters:   false
  doc:           """
The keyspec section is where you define critical metadata about chalk
keys.  The spec can even specify the value of the key.

There are four different kinds of keys:

1) Chalkable Host: Things that are not artifact specific, but either
                   are fixed, or are unique to the host or the run,
                   that *can* (and in some instances must) be placed in
                   chalks, or just captured as part of a report.
                   Plugins must make these available before the
                   chalk phase.

2) Chalk:          Keys that could have per-artifact values, and can be
                   chalked (i.e., they are determinable at chalk time).
                   Plugins can provide these early, if the value is
                   destined to be the same for every artifact, unless
                   the keyspec field "never_early" is true.

3) Non-Chalk:      Per-artifact keys that are *not* available at chalk
                   time. This can include immediately post-chalk, or
                   environmental items at the time or extraction or
                   other operations.

4) Host Only:      Per-run keys that are not available for chalking,
                   and also are never expected to be artifact-specific.

For clarity as to what is chalkable, all keys that are Post-Chalk or
Post-Run must start with a leading _.  No keys that are chalkable may
start with _.

The base chalk spec defines many metadata keys, but you may also
define your own, by adding your own keyspec sections, as long as they
start with either 'X-' (for keys that can appear in a chalk mark), or
'_X-' (for keys that are unchalkable metadata, often per-run keys).

Some fields in keyspecs will be overridable; for instance, you can set
default values or change output order priorities for many
keys. However, there will be some keys where the implementation must
be handled by the system to be conformant, or where there are
technical considerations the output should mirror (for instance, the
SIGNATURE should really go after everything being signed).

Generally, when reviewing specific keyspecs, when they have fields
with "write_lock" set, those fields will not be overwritable.

See "chalk help keys" or "chalk help key KEY_NAME" for specific key type
info.
"""

  field required {
    # Required fields apply only to what must go into a chalk mark.
    type:        bool
    default:     false
    write_lock:  true
    doc:         """
This field will only be true for keys that MUST be in a bare-minimum
chalk mark (even if the chalk mark is not inserted directly into the
artifact; so called 'virtual' chalk marks are expected to be put
elsewhere, but must still contain at least required keys.
"""
  }

  field kind {
    type:        int
    require:     true
    write_lock:  true
    range:       (ChalkableHost, HostOnly)
    doc: """
Specifies which of the four chalk key types applies for this key. While this
is an integer, there's an enumeration defined you can use:

ChalkableHost, Chalk, NonChalk, HostOnly
"""
  }

  field never_early {
    type:        bool
    default:     false
    write_lock:  true
    validator:   func never_early_check
    doc: """
True for keys of kind "Chalk" where it would never make sense
for a plugin to assign the same value to all keys.  For
instance, the repo URI *could* be different per-artifact, but
it's perfectly reasonable for a plugin to not check the repo
on each artifact, and assume the one in the CWD.

If metadata whose keys have 'never_early' set to 'false' are
placed in the host report but not the artifact report, then
they will only show up in the host report if the plugins
report them pre-chalking, or if every single chalk has the
same value.  Otherwise, the value will be skipped.

If you add to both the host and artifact report, host will
be preferred, but it will still show up per-artifact if
appropriate.
"""

  }

  field type {
    type:       typespec
    require:    true
    write_lock: true
    doc: """
The data type associated with the key. Generally, all keys should map
clearly to types supported by JSON.
"""
  }

  field standard {
    type:        bool
    require:     false
    stack_limit: 0
    hidden:      true
    doc:         """
Standard keys are those that are part of either the Chalk spec, or
the chalk internals (keys that start with $).  Non-standard keys
must meet the naming rules for user-defined keys.
"""
  }

  field system {
    type:       bool
    default:    false
    write_lock: true
    doc:        """
System keys may not be user-set, other than via the system plugin, or other
parts of the system implementation not part of the plugin system.  These keys
can never be redefined directly (though some may be indirectly set in codecs
by the methods they implement).
"""

  }

  field conf_as_system {
    type:        bool
    default:     false
    stack_limit: 0
    hidden:      true
    doc:         """
True if the value of a system key can actually be set by the conffile value
or callback field.  This is really an internal thing.
"""
  }

  field codec {
    type:       bool
    default:    false
    write_lock: true
    doc: "Codec keys may only be provided by codecs (and MUST be provided)."
  }

  field value {
    type:       "type"
    require:    false
    doc:        """
If nothing overrides, the conffile plugin will add these in.  Cannot appear
with a 'callback' field.
"""

  }

  field callback {
    type:       func (string) -> `x
    require:    false
    validator:  func key_callback_check
    doc:        """
If nothing overrides, the conffile plugin will call this for a value.  Cannot
appear with a 'value' field.
"""
  }

  field since {
    type:       string
    require:    false
    write_lock: true
    doc: "Version of the standard in which this key first appeared."
  }

  field normalized_order {
    type:        int
    default:     default_key_priority
    range:       (0, high())
    doc: """
The normalization order used for signing and hashing metadata.
This only works for built-in keys; everything else is given the same
priority and should be sorted alphabetically.
"""
  }

  field apply_substitutions {
    type:        bool
    default:     false
    write_lock:  true
    doc: """
For variables where this is true, the system will, immediately before signing
and computing a metadata hash, apply any appropriate variable substitutions.
Currently supported variable substitutions are:

{chalk_id} -> value of CHALK_ID
{now}      -> value of TIMESTAMP
{path}     -> value of ARTIFACT_PATH
{hash}     -> value of HASH
{tenant}   -> value of TENANT_ID
{random}   -> value of CHALK_RAND

Note that these substitutions currently only are applied to chalkable
keys, and those keys must not have been lifed into the host context by
whatever plugin collected them.
"""
  }

  field doc {
    type:     string
    require:  false
    hidden:   true
  }

  exclusions {
    value: "callback"
  }
}

object plugin {
  gen_fieldname: "plugins"
  gen_typename:  "PluginSpec"
  user_def_ok:   false
  gen_setters:   false

  field priority {
    type:     int
    default:  50
    range:    (0, high())
    doc: """
Plugins are called in priority order (lower numbers are higher
priority).  You can redefine this field for most of the builtin
plugins, with the exception of the system plugins that wrap the
process (particularly to ensure that all data is available both for
other plugins that might need it, and for metadata signing, which must
therefore come last).
"""
  }

  field ignore {
    type:    list[string]
    default: []
    doc:     "Keys from this plugin the user wishes to ignore."
  }

  field codec {
    type:       bool
    default:    false
    write_lock: true
    doc:        "This key must be set for all codecs."
  }

  field pre_run_keys {
    type:       list[string]
    default:    []
    write_lock: true
    validator:  func pre_run_key_check
    doc: "List of keys this plugin provides before our artifact collection."
  }

field artifact_keys {
    type:       list[string]
    default:    []
    write_lock: true
    validator:  func chalk_key_check
    doc:        """
List of keys this plugin provides during artifact collection.
If they are chalkable keys, they must only be provided during
chalk operations.  Non-chalkable per-artifact keys can always
be provided here if appropriate.
"""
  }

  field post_chalk_keys {
    type:       list[string]
    default:    []
    write_lock: true
    validator:  func post_chalk_key_check
    doc:        """
List of keys this plugin provides after an artifact is chalked,
before the next artifact is processed.
"""
  }

  field post_run_keys {
    type:       list[string]
    default:    []
    write_lock: true
    validator:  func post_run_key_check
    doc:        "List of keys this plugin provides after a run completes."
  }

  field enabled {
    type:    bool
    default: true
    doc:     "Setting this field completely disables a plugin."
  }

  field overrides {
    type:      list[string]
    default:   []
    validator: func override_key_check
    doc:       """
This field can be used to specify keys where this plugin's value
should be taken, even if a value has already been collected for
the key.  This is invalid for system keys.
"""
  }

  field doc {
    type:    string
    require: false
    hidden:  true
  }
}

object sink {
  gen_fieldname: "sinks"
  gen_typename:  "SinkSpec"
  gen_setters:   false
  user_def_ok:   true
  validator:     func sink_object_check
  doc:           """
This object type is needed to add new data sinks to chalk.  Note that
sinks configurations are loaded after all config files are run, so if
you want to add a sink_config object to configure one of these sinks,
and then you want to use that configuration in I/O immediately, you
need to call load_sink_configs() explicitly.

When adding a sink to Chalk, the fields you add should be the fields
you may take as parameters in a sink_config. All parameters will be of
type 'string'. If the parameter is required, then set the value to
'true'.  If it is not required, then set the value to 'false', unless
you want to provide a default value, in which case, set the value as a
string.

For the moment, each 'sink' object is expected to tie to a sink
implementation loaded in chalk.
"""

  field doc {
    type:    string
    require: false
    hidden:  true
  }
}

object sink_config {
  gen_fieldname: "sinkConfs"
  gen_typename:  "SinkConfigObj"
  gen_setters:   false
  user_def_ok:   true
  validator:     func sink_config_check
  doc: """
Configure a sink, using the fields provided in that sink spec.
"""

  field enabled {
    type:    bool
    default: true
    doc: """
Set to false to leave in the config but disable it.
"""
  }

  field filters {
    type:    list[string]
    default: []
    validator: func sink_filter_check
    doc: """
Filters to install.  Valid options are:
{bold}log_level{reset} -- Used for reporting to the log sink, this completely filters out messages that aren't as 'important' as the current log level.  The default output configuration has this installed.
{bold}log_prefix{reset} -- Used to add the name of the log level to log messages.  This is added in the default log configuration.
{bold}pretty_json{reset} -- Assumes the input is JSON, and then formats it for human output, mainly adding newlines and a bit of indentation.
{bold}fix_new_line{reset} -- Add a newline to the end of any published message if it doesn't already have one.
{bold}add_topic{reset} -- Not used by default, but adds a header to any message noting the topic.
{bold}wrap{reset} -- Wrap text, taking the current terminal width into account.
"""
  }

  field sink {
    type:       string
    default:    ""  # Will cause this to get ignored.
    write_lock: true
    doc: "The base sink; other attrs in this section are based on this value."
  }
}

object outconf {
  gen_fieldname: "outputConfigs"
  gen_typename:  "OutputConfig"
  gen_setters:   false
  user_def_ok:   false
  doc:           """
Binds profiles to commands.  The only valid object names for outconf sections
are the names of valid chalk commands.  There are default profiles with
reasonable defaults for every command.
"""

  field chalk {
    type:      string
    default:   ""
    validator: func outconf_chalk_check
    doc:       """
This profile is only allowed for commands that create chalk objects, and
governs what will be put into the chalk mark.
"""
  }

  field artifact_report {
    type:      string
    default:   ""
    validator: func outconf_artifact_check
    doc:       """
The named profile is used for when reporting on per-artifact any
information, so works with any command. If both this field and the
'invalid_chalk_report' field are defined, then this profile gets used
when the extracted chalk mark fully validates.  That DOES generally
require you to be using signatures, though at some point we may
optionally allow validation to be considered 'successful' only if the
integrity check passes, even if this makes marks forgable.
"""
  }

  field invalid_chalk_report {
    type:      string
    default:   ""
    validator: func outconf_invalid_chalk_check
    doc:       """
The named profile is used for reporting per-artifact, any time the
digital signature is fully validated. The general idea here is that,
if you like, you can minimize the amount of data you send back to a
server by only retrieving a minimal amount of data, and only send up
full chalks when chalks do not validate.

That could be useful when you've performed the chalk operation, so
validation helps ensure you already have the rest of the information
server-side.

However, there is currently no easy mechanism for checking to see if
you already know about this chalk mark. If it was chalked from some
other organization, but the validation check is passed, you will still
get this profile.

As a result, our preferred method for dealing with duplicate info is
to check the METADATA_ID server-side before insertion into any data
store.

However, if you choose to save on bandwidth, we recommend you pass
back enough identifying information (via non-chalk per-artifact keys),
that you can re-run chalk forcing a different profile (and ideally in
a way you fully automate).
"""
  }

  field host_report {
    type:      string
    default:   ""
    validator: func outconf_host_check
    doc:       """
The named profile is used to determine which host-level metadata keys
will be used in the report.  Note that, without this report enabling
the '_CHALKS' key, *NO* artifact-level information will be reported,
which generally makes managing chalk information harder, since the
artifact will, at the point of chalk, be the sole record of the mark.
"""
  }

  field doc {
    type:     string
    require:  false
    hidden:   true
  }
  doc: """
Specifies what reporting profiles to use for I/O on a per-command
basis. Only valid chalk commands are valid section names.
"""
}

object custom_report {
  gen_fieldname: "reportSpecs"
  gen_typename:  "ReportSpec"
  gen_setters:   false
  user_def_ok:   false
  doc:           """
The custom_report object allows you to create secondary reports for
whatever purpose.  The built-in 'audit' capability uses this (when
enabled) to store information about the configuration used when chalk
runs.

Similarly, it can be used for reporting summary statistics, for
instance, simply sending an empty message to mark when the executable
is run.

Or, you can use this to implement a second report with different data
fields that goes to a data lake for analysis, or to the local file
system as a failsafe if there are network connectivity problems.
"""

  field enabled {
    type:      bool
    default:   true
    doc:       """
For any custom report, this field must be set to 'true' for chalk to
run the report.

Even for the built-in audit report, if you override this field, the
audit report will not run, even if you've set the option to enable
auditing.

Custom reports never chalk; you must use the appropriate 'outconf'
report.
"""
}

  field sink_configs {
    type:      list[string]
    require:   true
    validator: func sink_list_check
    doc: """
A list of sink configurations that should be subscribed to this report.
Basically, this controls where your report will output.
"""
  }

  field artifact_profile {
    type:       string
    default:    ""
    validator:  func custom_report_artifact_check
    doc:        """
The named profile is used for when reporting on per-artifact any
information. If both this field and the 'invalid_chalk_profile' field
are defined, then this profile gets used when the extracted chalk mark
fully validates.  That DOES generally require you to be using
signatures, though at some point we may optionally allow validation to
be considered 'successful' only if the integrity check passes, even if
this makes marks forgable.
"""
  }

  field invalid_chalk_profile {
    type:       string
    default:    ""
    validator:  func custom_report_artifact_check
    doc:        """
If provided, this is the profile used for non-validating chalks, instead of
the profile given in artifact_profile.  See the 'outconf' field
'invalid_chalk_report' for considerations.
"""
  }

  field host_profile {
    type:      string
    default:   ""
    validator: func custom_report_host_check
    doc:       """
The named profile is used to determine which host-level metadata keys
will be used in any report.  Note that, without this report enabling
the '_CHALKS' key, *NO* artifact-level information will be reported.
"""
  }

  field use_when {
    type:      list[string]
    default:   ["*"]
    validator: func use_when_check
    doc:       """
This field allows you to specify (without conditional logic in the
configuraiton file), the chalk commands that will trigger this report.
That is, if the current chalk command is not in this list, then the
report will NOT run.

If not specified, reports apply to any command that reports.
"""
  }

  field doc {
    type:     string
    require:  false
    hidden:   true
  }
}

singleton docker {
  gen_fieldname: "dockerConfig"
  gen_typename:  "DockerConfig"
  gen_setters:   false
  user_def_ok:   false
  doc: """
Internal configuration information for the docker command.
"""
  allow getopts { }
  #% INTERNAL
  field wrap_entrypoint {
    type:    bool
    default: false
    doc:     """
When running the docker command, this option modifies the container
to, on entry, report as if running the 'chalk extract' command, and
then exec the actual entry point.
"""
  }

  field entrypoint_report_sink {
     type:      string
     default:   ""
     validator: func sink_ref_check
     doc:  """
When wrapping a container to run in entrypoint mode, you need to configure an output sink.  For this, specify the name of a sink configuration.
"""
  }

  field entrypoint_host_report_profile {
    type:      string
    require:   false
    validator: func custom_report_artifact_check
    doc:       """
The named profile is used to determine which host-level metadata keys
will be used for reporting when a docker container entry point is run.
If not provided, a default policy is added.
"""
  }

  field entrypoint_artifact_report_profile {
    type:      string
    require:   false
    validator: func custom_report_artifact_check
    doc: """
The named profile is used for when reporting on per-artifact any
information, when run from the docker entry point.
If not provided, a default policy is added.
"""
  }
#% END
  field chalk_file_location {
    type: string
    default: "/chalk.json"
    doc: """
This controls where the chalk file gets written.  Should generally be in the root, just in case the path doesn't exist in a container.
"""
  }

  field label_prefix {
    type:    string
    default: "run.crashoverride."
    validator: func label_prefix_check
    doc: """
When locker labels are used, they are supposed to have a reverse-DNS prefix for the organization that added them. You generally should add your own organization here.
"""
  }

  field label_profile {
    type:    string
    default: "chalk_labels"
    validator: func label_profile_check
    doc: """
This profile guides what labels will be automatically added to docker images when we successfully chalk them. The only allowed keys are Chalk keys and Chalkable Host keys.  And, if the metadata is not available, then no key will be added.
For instance, the HASH key cannot currently appear in docker chalks, because it is not available for docker chalking, so will not appear as a label.  But, you can add METADATA_ID, CHALK_ID, etc. or anything else that is collectable before the build.
"""
  }

  field custom_labels {
    type: dict[string, string]
    require: false
    validator: func custom_labels_check
    doc: """
Any labels added here will be added as a LABEL line to the chalked container.  This will add label_prefix before the keys, and will not add if the key is not an alphanumeric value.
"""
  }

  field report_unwrapped_commands {
    type:    bool
    default: false
    doc: """
If true, host reports will be generated for docker commands we do not wrap.
By default, we do not report.  If you set this to 'true', it's helpful to 
have _ARGV in your report, to get more telemetry.
"""
  }
}

root {
  prologue: """
# This file is auto-generated as part of the chalk build.
# Please do NOT edit it. Edit the specification file from
# which it was generated instead: src/configs/chalk.c42spec
# That will trigger a rebuild.

"""
  gen_typename: "ChalkConfig"
  gen_setters:  false
  user_def_ok:  false

  allow keyspec       { }
  allow plugin        { }
  allow sink          { }
  allow sink_config   { }
  allow profile       { }
  allow outconf       { }
  allow custom_report { }
  allow tool          { }
  allow docker        { }

  field config_path {
    type:       list[string]
    default:    [".", "~/.config/chalk", "~"]
    write_lock: true
    doc:        "The path to search for an external configuration file."
    shortdoc:   "Configuration Path"
  }

  field config_filename {
    type:       string
    default:    "chalk.conf"
    write_lock: true
    doc:        "The file name to look for when searching for a file"
    shortdoc:   "Configuration File Name"
  }

  field valid_chalk_command_names {
    type:       list[string]
    default:    all_cmds_that_insert
    write_lock: true
    hidden:     true
    doc:        "Expose command names used for insertion to the implementation"
  }

  field valid_chalk_commands {
    type:       list[string]
    default:    valid_chalk_cmds
    write_lock: true
    hidden:     true
    doc:        "Expose the full list of command names to the implementation"
  }

  field ignore_when_normalizing {
    type:       list[string]
    default:    ["MAGIC", "METADATA_HASH", "METADATA_ID", "SIGN_PARAMS",
                 "SIGNING", "SIGNATURE", "EMBEDDED_CHALK"]
    write_lock: true
    hidden:     true
    doc:        """
This is a list of fields that are chalkable, that will not ever be included in
normalization operations used for computing metadata hashes and signatures.
"""
  }

  field default_command {
    type:       string
    require:    false
    write_lock: false
    validator:  func default_command_check
    shortdoc:   "Default Command (when not provided)"
    doc:        """
If no top-level command is passed on the command line, this command is
assumed.  By default, if the config file does not resolve the ambiguity,
then chalk will produce a help message.
"""
  }

  field selected_command {
    type:       string
    default:    ""
    write_lock: false
    shortdoc:   "The command we just ran"
    doc:        """

Once the command line is fully parsed, this will get the value of the
selected command.  If the command is ambiguous, fill it in with the
value 'default_commmand'.

In that case, this field doesn't get set with a real value until after
all your configuration files run.  Instead, it will be an empty
string.
"""
  }

  field color {
    type:     bool
    require:  false
    shortdoc: "Show Colors"
    doc: """
Whether to output ANSI color. If this is not explicitly set, will respect
the presense of a NO_ANSI environment variable, but is otherwise on by default.
"""
  }

  field log_level {
    type:     string
    default:  "warn"
    choice:   valid_log_levels
    shortdoc: "Console Log Level"
    doc: """
Determines what kind of logging messages show to the console. To see
everything, use 'trace' or 'verbose' (they are aliases).
"""
  }

  field chalk_log_level {
    type:     string
    default:  "error"
    choice:   valid_log_levels
    shortdoc: "Reporting Log Level"
    doc:      """
Determines what kind of logging messages will be added to metadata via the
ERR_INFO or _ERR_INFO keys. During the chalk phase of chalking ops only,
per-object errors that are at least as severe as specified will be added to
the object's  ERR_INFO field.

Everything else will go to _ERR_INFO.
"""
  }

  # Chalk posts to 'virtual' topic instead of calling insert.
  field virtual_chalk {
    type:     bool
    default:  false
    shortdoc: "Virtual Chalk Mode"
    doc:      """
This option implements 'virtual' chalking, where the chalk mark is not
inserted into an artifact via codec. Instead, the chalk mark gets
published to the "virtual" topic, and it is the user's responsibility
to do something about it.  Or else, you could treat it as a dry-run mode.

By default, virtual chalk marks will get appended to {bold}"./virtual-chalk.json"{reset}, but you can use the output system to send them anywhere (this is setup in the default configuration file).
"""
  }

  field zip_extensions {
    type:       list[string]
    default:    ["zip", "jar", "war", "ear"]
    validator:  func zip_check
    hidden:     true
    doc:        "Extensions that we assume are in ZIP format for the zip codec"
  }

  field py_extensions {
    type:       list[string]
    default:    ["py", "pyw", "ipy"]
    validator:  func py_check
    hidden:     true
    doc:        "Extensions that we assume are Python source files for the python .py codec"
  }

    field pyc_extensions {
    type:       list[string]
    default:    ["pyc", "pyo", "pyd"]
    validator:  func pyc_check
    hidden:     true
    doc:        "Extensions that we assume are Python bytecode files for the python .pyc codec"
  }

  field con4m_pinpoint {
    type:    bool
    default: true
    hidden:  true
    doc:     """
When outputting errors in the config file, try to put a marker under the line
where the compiler found an error to show the exact location.
"""
  }

  field chalk_debug {
    type:    bool
    default: false
    hidden:  true
    doc:     "Show Nim stack traces, including for con4m errors."
  }

  field cache_fd_limit {
    type:    int
    default: 50
    range:   (0, high())
    hidden:  true
    doc:     """
We are caching file descriptors, because the original implementation would scan
everything before chalking anything. This is no longer done, so this code is no
longer necessary, and we will remove this at some point.
"""
  }

  field publish_audit {
    type:       bool
    default:    false
    write_lock: true
    shortdoc:   "Run Audit Report"
    doc:        """
This controls whether the default 'usage' audit is published. The
usage audit is a pre-configured report called 'audit'.

By default, it is hooked up to a file sink, the location of which is
specified by the audit_location variable.
"""
  }

  field audit_location {
    type:       string
    default:    "./.chalk-audit.jsonl"
    shortdoc:   "Audit file location"
    doc:  """
This controls where the default audit log goes, if enabled.  If you enable
and set this to "", then you need to provide your own output configuration
that subscribes to the 'audit' topic.
./chalk-audit.jsonl
"""
  }

  field artifact_search_path {
    type:     list[string]
    default:  ["."]
    shortdoc: "Search Path"
    doc:      """
Set the default path to search for artifacts, unless overriden by
 command-line arguments.
"""
  }

  field ignore_patterns {
    type:     list[string]
    default:  [".*/**", "*.txt", "*.json"]
    shortdoc: "Ignore Patterns"
    doc:       """
For operations that insert or remove chalk marks, this is a list of
regular expressions for files to ignore when scanning for artifacts to
chalk.

The 'extract' operation ignores this.
"""
  }

  field load_external_config {
    type:     bool
    default:  true
    shortdoc: "Run any external configuration file, if found"
    doc: """
Turn this off to prevent accidentally picking up an external configuration file. You can always re-enable at the command line with --yes-external-config
"""
  }

  field load_embedded_config {
    type:     bool
    default:  true
    shortdoc: "Run the embedded configuration file"
    doc: """
This variable controls whether the embedded configuration file runs. Obviously, setting this from within the embedded configuration file is pointless, as it's used before then. But, you can set this with --no-embedded-config at the command line.

This is primarily meant to make it easier to test new configurations by disabling the embedded config and only running the external (candidate) config.
"""
  }

  field load_default_signing {
    type:     bool
    default:  true
    shortdoc: "Load GPG module"
    hidden:   true # This happens before the user config runs.
    doc: """
When true, this will cause chalk to load the default signing
implementation, which provides an implementation of sign() an verify
that will use gpg, when available.  It makes no attempt to install GPG
if it is not available.

This implementation expects that the passphrase for signing will be
found in the GPG_PASSPHRASE environment variable.  The variable name
can be changed by setting the global variable PASSPHRASE_ENV_VAR with
the := operator (it is *not* an attribute).
"""
  }

  field run_sbom_tools {
    type:     bool
    default:  false
    shortdoc: "Run any configured SBOM tools"
    doc: """
When true, this will cause chalk to run any configured and enabled SBOM tool implementations. Currently, this is just syft, which will be downloaded into /tmp if not found on the system.

You can change that directory by setting the global variable SYFT_EXE_DIR with the := operator (it is *not* an attribute).

The syft command line arguments used at invocation (minus the target location) can be set via the SYFT_ARGV global variable.  It's default value is:

-o cyclonedx-json 2>/dev/null
"""
  }

  field run_sast_tools {
    type:     bool
    default:  false
    shortdoc: "Run any configured SAST tools"
    doc: """
When true, this will cause chalk to run any configured static analysis security testing (SAST) tools.  This is off by default, since it could add a noticable delay to build time for large code bases.

Currently, the only available tool out of the box is semgrep, and will only work on machines that either already have semgrep installed, or have Python3 installed.
"""
  }

  field recursive {
    type:     bool
    default:  true
    shortdoc: "Recursive"
    doc:      """
When scanning for artifacts, if this is true, directoris in the
artifact search path will be traversed recursively.
"""
  }

  field container_image_id {
    type:     string
    default:  ""
    hidden:   true
    shortdoc: "Image ID"
    doc:      """
This field should generally be passed at the command line. It is only
intended for manually 'virtually' chalking containers, and should
contain the ascii SHA256 hash of a container, which will be taken as
the artifact's hash.
"""
  }

  field container_image_name {
    type:     string
    default:  ""
    hidden:   true
    shortdoc: "Image Name"
    doc:      """
This field should generally be passed at the command line. It is only
intended for manually 'virtually' chalking containers, and should be
the image name, which will be put into the ARTIFACT_PATH field.
"""
  }

  field docker_exe {
    type:     string
    require:  false
    shortdoc: "Docker command location"
    doc: """
When running the 'docker' command, this tells chalk where to look for the docker executable to exec.

If this is not provided, or if the file is not found, chalk will search the PATH for the first instance of 'docker' that is not itself (We generally expect renaming chalk to docker and using this variable to point to the actual docker EXE will be the most seamless approach).

Note that, when chalk is invoked with 'docker' as its EXE name, the default IO configuration is to *NOT* anything chalk-specific on the console.
"""
  }

  field chalk_contained_items {
    type:    bool
    default: true
    shortdoc: "Add chalk to embedded chalkable objects"
    doc: """
When chalking an artifact that can itself contain artifacts, this field dictates whether the contents should be chalked, or if just the outer artifact.  This also controls whether, on extraction, chalk will report contents.

Currently, this is only respected for artifacts in ZIP format (e.g., JAR files)
"""
  }

  field publish_defaults {
    type:       bool
    default:    false
    write_lock: true
    shortdoc:   "Publish Defaults"
    doc:        """
When set to true, configuration information will be published to the
"defaults" topic, which, by default, will print to stderr.

This is similar to the 'chalk defaults' command, except that it causes
the same type of information to be added at the end of *any*
operation.

This is useful when you have conditional logic in your configuration
file, and want to see the results of config file evaluation for
specific sets of command-line arguments.
"""
  }

  field ktype_names {
    type:       list[string]
    default:    key_types
    write_lock: true
    hidden:     true
    doc:        "Internal; used to map key type enum values back to text."
  }

  field defaults_disclaimer {
    type:       string
    hidden:     true
    doc:        "Externalize disclaimer string."
    write_lock: true
    default:  """
Note that these values can change based on logic in the config file.  You can cause the current configuration to be published to the 'defaults' topic on any run by setting 'publish_defaults' in the con4m configuration or passing '--publish-defaults' on the command line.

Note that '--no-publish-defaults' at the command line will block this feature, even if the configuration file asks for it to be used. Running the 'defaults' command always publishes, though.
"""
  }
  field use_report_cache {
    type:       bool
    default:    false
    shortdoc:   "Report cache on"
    doc:       """
The report cache is a self-truncating local log file, indended to add protection
against reporting not reaching its destination. This is obviously not worthwhile
for transient infrastructure. In such a case, configure and attach multiple
 sinks instead.

Note that this can be set on the command line with --log.
"""
  }

  field report_cache_location {
    type:       string
    default:    "./chalk-reports.jsonl"
    shortdoc:   "Report cache location"
    doc:        "Where to write the report cache, if in use."
  }

  field report_cache_size {
    type:       Size
    shortdoc:   "Report cache size"
    default:    <<10mb>>
    doc:        """
If a write to the cache would exceed this amount, the system will truncate down to 75% of this size before doing the write.
"""
  }

  field env_always_show {
    type:       list[string]
    default:    []
    shortdoc:   "Env Vars to show full data for"
    doc:        """
For the ENV and _ENV metadata keys, any environment variable listed here will get reported with its actual value at the time the chalk command is invoked.
"""
  }

  field env_never_show {
    type:       list[string]
    default:    []
    shortdoc:   "Env Vars to ignore"
    doc:        """
For the ENV and _ENV metadata keys, any environment variable listed here will get ignored.
"""
  }

  field env_redact {
    type:       list[string]
    default:    []
    shortdoc:   "Env Vars to redact"
    doc:        """
For the ENV and _ENV metadata keys, any environment variable listed here will get redacted for privacy.  Currently, that means we give the value <<redacted>>; we do not try to detect sensitive data and redact it.
"""
  }

  field env_default_action {
    type:     string
    choice:   ["show", "redact", "ignore"]
    default:  "redact"
    shortdoc: "Default envvar action"
    doc:        """
For the ENV and _ENV metadata keys, any environment variable that is not listed explicitly in the above lists will be handled as specified here.
"""
  }
  #% INTERNAL
  field entrypoint {
    type:    string
    require: false
    doc:  """
When running in entrypoint mode, this is the command line to exec on startup.
Note that this is generally set by the 'docker' command.  If it is set, then
command line parsing won't happen.
"""
  }
  #% END

  field crashoverride_usage_reporting_url {
    type:       string
    default:    "https://chalk.crashoverride.run/report"
    hidden:     true
    doc:        "Used to approximate overall chalk usage. See the usage report"
  }

  field crashoverride_workspace_id {
    type:       string
    default:    "470f1ff7-8b26-43a5-a31d-45c2fcecfaa2"
    hidden:     true
    doc:        "The default value is the one used for anonymous users."
  }
}

func keyspec_exists(name) {
  if sections("keyspec").contains(name) { return true; }
  return false
}

func key_callback_check(keyname, callback: func (string) -> `x) {
  path      := split(keyname, ".")
  key_name  := path[1]
  fieldType := $(attr_get("keyspec." + key_name + ".type", typespec))
  expected  := to_type("(string) -> " + fieldType)
  actual    := typeof(callback)

  if not typecmp(expected, actual) {
    return ("In: '" + keyname + "' callback is of type '" + $(actual) +
            "', but the key specification requires the type: '" +
  	    $(expected) + "'")
  }

  return ""
}

func never_early_check(keyname, val) {
  result := ""

  if val == true {
    path       := split(keyname, ".")
    kind_field := "keyspec." + path[1] + ".kind"
    kind       := attr_get(kind_field, int)

    if kind != Chalk {
      return "'never_early' can only be set for fields of type Chalk"
    }
  }
}

func plugin_keyspec_check(keyname, val: list[string], context) {
  result := "" # Default on success

  # For each key in val...
  # 1) If the key doesn't exist, fail.
  # 2) If the key exists, it must be either of kind ChalkableHost or Chalk
  # 3) If it's of type chalk, never_early must be false.

  for i from 0 to len(val) {
    item := val[i]

    if item == "*" { continue; }

    if not keyspec_exists(item) {
      return (keyname + ": specified key '" + item + "' does not have an " +
        "associated keyspec")
    }

    base              := "keyspec." + item + "."
    kind_field        := base + "kind"
    kind              := attr_get(kind_field, int)

    if context == CCPreRun {
      if kind == ChalkableHost { continue }
      elif kind == Chalk {
        never_early_field := base + "never_early"
        if attr_get(never_early_field, bool) == false {
  	  continue
	}
      }
      return (keyname + ": specified key '" + item + "' cannot appear in " +
             "the 'Pre-Run' collection context")
    }
    elif context == CCArtifact or context == CCPostChalk {
      if kind == HostOnly or (kind == ChalkableHost and context == CCPostChalk) {
        return (keyname + ": specified key '" + item + "' is a host-level " +
	        "key that cannot appear at artifact collection time")
      }
      if context == CCPostChalk and kind == Chalk {
        return (keyname + ": specified key '" + item + "' must be available " +
	       "during artifact collection")
      }
    }
    else {  # context == CCPostRun
      if kind == HostOnly { continue }

      return (keyname + ": specified key '" + item + "' cannot appear in " +
              " the 'Post-Run' collection context")
    }
  }
}

func pre_run_key_check(keyname, val) {
  return plugin_keyspec_check(keyname, val, CCPreRun)
}

func chalk_key_check(keyname, val) {
  return plugin_keyspec_check(keyname, val, CCArtifact)
}

func post_chalk_key_check(keyname, val) {
  return plugin_keyspec_check(keyname, val, CCPostChalk)
}

func post_run_key_check(keyname, val) {
  return plugin_keyspec_check(keyname, val, CCPostRun)
}

func override_key_check(keyname: string, val: list[string]) {
  result := ""
  parts := keyname.split(".")
  base  := "plugin." + parts[1] + "."
  k1    := attr_get(base + "pre_run_keys",    list[string])
  k2    := attr_get(base + "artifact_keys",   list[string])
  k3    := attr_get(base + "post_chalk_keys", list[string])
  k4    := attr_get(base + "post_run_keys",   list[string])

  for i from 0 to len(val) {
    if k1.contains(val[i]) or k1.contains("*") { continue; }
    if k2.contains(val[i]) or k2.contains("*") { continue; }
    if k3.contains(val[i]) or k3.contains("*") { continue; }
    if k4.contains(val[i]) or k4.contains("*") { continue; }
      return (keyname + ": Plugin does not produce the metadata key: '" +
             val[i] + "'" )

  }
}

func pc_err(profile, key, err) {
  return ("Profile '" + profile + "' specifies reporting key '" + key +
           "', but " + err)
}

func profile_check_base(profile_name, profile_type) {
  result := ""
  sects  := sections("profile")

  if profile_name == "" {
    return
  }
  if not sects.contains(profile_name) {
    return "profile '" + profile_name + "' not found"
  }

  specs        := sections("keyspec")
  profile_keys := sections("profile." + profile_name + ".key")

  for i from 0 to len(profile_keys) {
    if not specs.contains(profile_keys[i]) {
        return ("profile '" + profile_name + "' contains a key: '" +
                profile_keys[i] + "', which has no associated keyspec.")
    }
  }
  for i from 0 to len(specs) {
    key_name   := specs[i]
    key_kind   := attr_get("keyspec." + key_name + ".kind", int)

    if not profile_keys.contains(key_name) {
      if profile_type == PTChalk {
        if key_kind == NonChalk or key_kind == HostOnly { continue }
        if attr_get("keyspec." + key_name + ".required", bool) == true {
          return pc_err(profile_name, key_name,
                        "that key is required to be in chalk marks.")
        }
      }
      continue
    }

    keyconfbase := "profile." + profile_name + ".key." + key_name + "."
    if attr_get(keyconfbase + "report", bool) == false {
      if profile_type == PTChalk {
        if key_kind == NonChalk or key_kind == HostOnly { continue }
        if attr_get("keyspec." + key_name + ".required", bool) == true {
          return pc_err(profile_name, key_name,
                        " that key is required to be in chalk marks.")
        }
      }
      continue
    }
    elif profile_type == PTChalk {
      continue
    }

    # By here, we know this profile wants to set this key explicitly,
    # and that we are not in a chalk profile.
    #
    # - ChalkableHost keys can appear anywhere.
    # - Chalk keys can appear in per-artifact reports, and in host-reports
    #   as long as the keyspec set never_early to 'false'
    # - NonChalk keys can appear in per-artifact reports only.
    # - HostOnly keys can appear in host reports only.
    #
    # If the profile type is PTChalkTimeArtifact, we don't allow NonChalk
    # or HostOnly keys.

    if profile_type == PTArtifact or profile_type == PTChalkTimeArtifact {
      if key_kind == HostOnly {
        return pc_err(profile_name, key_name,
                      "that key cannot appear in artifact report spec")
      }
      if key_kind == NonChalk and profile_type == PTChalkTimeArtifact {
        return pc_err(profile_name, key_name, "This report is used at build " +
	"time, so keys collected post-chalk aren't allowed.")
      }
      continue
    }
    # Else, profile type is PTHost
    if key_kind == NonChalk {
       return pc_err(profile_name, key_name,
          "non-chalkable artifact info can't be in a host-level report spec")
    }
    elif key_kind == Chalk {
      if attr_get("keyspec." + key_name + ".never_early", bool) == true {
        return pc_err(profile_name, key_name,
        "that key is artifact specific, so can't be in host-level report spec")
      }
    }
    # Otherwise, all is good in the cosmos.
  }
}

func in_outconf(name) {
  secname := name.split(".")[1]
  return "In outconf section '" + secname + "': "
}

func in_report(name) {
  reportname := name.split(".")[1]
  return "In custom report '" + reportname + "': "
}

func outconf_chalk_check(name, profile_name) {
  if profile_name == "" { return ""; }
  result := ""
  path   := split(name, ".")
  cmd    := path[1]

  if not contains(all_cmds_that_insert, cmd) {
    return (in_outconf(name) + "' Cannot have a chalk profile; " +
            "It's only valid for commands that add chalk marks.")
  }

  result := profile_check_base(profile_name, PTChalk)
  if result != "" {
    result := in_outconf(name) + result
  }
}

func outconf_artifact_check(name, profile_name) {
  if profile_name == "" {
    return ""
  }
  result := profile_check_base(profile_name, PTArtifact)
  if result != "" {
    result := in_outconf(name) + result
  }
}

func outconf_host_check(name, profile_name) {
  if profile_name == "" {
    return ""
  }
  result := profile_check_base(profile_name, PTHost)
  if result != "" {
    result := in_outconf(name) + result
  }
}

func outconf_invalid_chalk_check(name, profile_name) {
  result := ""
  path   := split(name, ".")
  cmd    := path[1]

  if profile_name == "" {
    return ""
  }

 if contains(all_cmds_that_insert, cmd) {
    return (in_outconf(cmd) + "' Cannot have an invalid chalk profile; " +
            "It's only valid for commands that do NOT add chalk marks.")
  }

  result := profile_check_base(profile_name, PTArtifact)
  if result != "" {
    result := in_outconf(name) + result
  }
}

func custom_report_artifact_check(name, profile_name) {
  result := profile_check_base(profile_name, PTArtifact)
  if result != "" {
    result := in_report(name) + result
  }
}

func label_profile_check(name, profile_name) {
  if profile_name == "" {
    return ""
  }
  result := profile_check_base(profile_name, PTChalkTimeArtifact)
  if result != "" {
    result := in_report(name) + result
  }
}

func is_valid_label(label) {
  result := true
  chars := to_chars(label)
  l     := chars.len()
  for i from 0 to l {
    c := chars[i]
    if is_alphanum(c) {
      continue
    }
    if contains(['.', '-', '$'], c) {
      continue
    }
    return false
  }
}

func label_prefix_check(name, value) {

  if value.is_valid_label() {
    return ""
  } else {
    return ("Docker label prefix must only contain letters, numbers, " +
            "'.' or '-' (when processing label '" + value + "'")
  }
}

func custom_labels_check(name, value) {
  result := ""
  stuff := value.keys()
  l     := len(stuff)
  for i from 0 to l {
    if not is_valid_label(stuff[i]) {
      return ("Docker label prefix must only contain letters, numbers, " +
              "'.' or '-' (when processing label '" + stuff[i] + "'")
    }
  }
}

func sink_ref_check(name, sink_config_name) {
  result := ""

  # No sink config means use the default crashoveride one.
  if sink_config_name == "" { return; }
  if not sections("sink_config").contains(sink_config_name) {
    return "No sink configuration named: '" + sink_config_name + "'"
  }
}

func use_when_check(name, value: list[string]) {
  result := ""

  if value.contains("*") {
    if value.len() > 1 {
      return "For field use_when, '*' should be the only item when it appears"
    }
    return
  }
  for i from 0 to value.len() {
    if valid_chalk_cmds.contains(value[i]) {
      continue
    }
    return ("'use_when' must be a valid chalk command-line command, or a '*' " +
           " to indicate all commands. '" + value[i] +
	   "' isn't a chalk command")
  }
}

func custom_report_host_check(name, profile_name) {
  result := profile_check_base(profile_name, PTHost)
  if result != "" {
    result := in_report(name) + result
  }
}

func sink_check(name, sink: string) {
  if not attr_get("private_installed_sinks", list[string]).contains(sink) {
    report := name.split(".")[1]

    return ("The report '" + report + "' applies sink configuration '" + sink +
           "', but that configuration has not been set.")
  }
}

func sink_list_check(name, sinklist: list[string]) {
  result := ""
  for i from 0 to len(sinklist) {
     result := sink_check(name, sinklist[i])
     if result != "" { return; }
  }
}

func sink_filter_check(name, filterList: list[string]) {
  result := ""
  for i from 0 to len(filterList) {
    if not known_sink_filters.contains(filterList[i]) {
      return "Unknown filter in sink configuration: " + filterList[i]
    }
  }
}

# TODO: should add a "choices" constraint to con4m.
func zip_check(keyname: string, value: list[string]) {
  valid_items := ["zip", "jar", "war", "ear"]

  for i from 0 to len(value) {
    if not contains(valid_items, value[i]) {
      return "'" + value[i] + "' is not a supported zip-based file extension."
    }
  }
  return ""
}

func py_check(keyname: string, value: list[string]) {
  valid_items := ["py", "pyw", "ipy"]

  for i from 0 to len(value) {
    if not contains(valid_items, value[i]) {
      return "'" + value[i] + "' is not a supported python source file extension."
    }
  }
  return ""
}

func pyc_check(keyname: string, value: list[string]) {
  valid_items := ["pyc", "pyo", "pyd"]

  for i from 0 to len(value) {
    if not contains(valid_items, value[i]) {
      return "'" + value[i] + "' is not a supported python bytecode file extension."
    }
  }
  return ""
}

func default_command_check(keyname, value) {
  if contains(valid_chalk_cmds, value) or find(value, "help.") == 0 {
    return ""
  }
  return ("The attribute 'default_command' is set to '" + value +
          "', which is not a valid chalk command. Must be one of: " +
	  join(valid_chalk_cmds, ", "))
}

# Run any checks across fields that we haven't yet done...
func custom_report_extra_validation() {
  result       := ""
  report_sects := sections("custom_report")
  for i from 0 to len(report_sects) {
    base := "custom_report." + report_sects[i] + "."
    s1   := attr_get(base + "artifact_profile", string)
    s2   := attr_get(base + "host_profile", string)
    if s1 == "" and s2 == "" {
      return "Custom Report '" + report_sects[i] + "' must set a valid profile"
    }
  }
}

func key_name_validation() {
  result     := ""
  spec_sects := sections("keyspec")
  for i from 0 to len(spec_sects) {
    key_name := spec_sects[i]
    base     := "keyspec." + key_name + "."
    if attr_get(base + "standard", bool) { continue; }
    kind     := attr_get(base + "kind", int)
    if kind == ChalkableHost or kind == Chalk {
      if key_name.find("X-") == 0 { continue; }
    }
    elif key_name.find("_X-") == 0 { continue; }
    return ("Custom key '" + key_name + "' is invalid. Chalkable custom " +
            "keys must start with X- (or _X- for non-chalkable keys)")
  }
}

func sink_object_check(path) {
  result := ""
  f := fields(path)

  for i from 0 to len(f) {
    fieldname := path + "." + f[i]
    fieldtype := attr_type(fieldname)
    if typecmp(fieldtype, bool) or typecmp(fieldtype, string) {
      continue
    }
    return ("All sink fields must be a bool indicating whether a field is " +
            "required, or a string specifying a default value " +
	    "(offending field: '" + f[i] + "' has type: " + $(fieldtype))
  }
}

sink_config_skip_fields := ["enabled", "loaded", "sink", "filters"]
export sink_config_skip_fields

func sink_config_check(path) {
  result   := ""
  sinkname := attr_get(path + ".sink", string)
  if sinkname == "" {
    return # Unconfigured.
  }
  if not attr_exists("sink." + sinkname) {
    return "No such sink configured: '" + sinkname + "'"
  }
  sinkfields := fields("sink." + sinkname)
  conffields := fields(path)

  for i from 0 to len(conffields) {
    conffield := conffields[i]
    if sink_config_skip_fields.contains(conffield) {
      continue
    }

    if not sinkfields.contains(conffield) {
      return ("sink config provides field '" + conffield +
              "', but the specified sink '" + sinkname +
	      "' does not use that field.")
    }
    if not typecmp(attr_type(path + "." + conffield), string) {
      return "All sink_config fields must be strings."
    }
  }

  for i from 0 to len(sinkfields) {
    fullname := "sink." + sinkname + "." + sinkfields[i]
     t := attr_type(fullname)
     if not typecmp(t, bool) {   # TODO-- short circuit didn't work??
       continue
     }
     if not attr_get(fullname, bool) {
       continue
     }
     if not conffields.contains(sinkfields[i]) {
       return "sink config is missing required field: '" + sinkfields[i] + "'"
     }
  }
}

func final_check() {
  result := key_name_validation()
  if result != "" { return; }
  result := custom_report_extra_validation()
  if result != "" { return; }
}
