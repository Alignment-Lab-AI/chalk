## This is the con4m specification to enable con4m to automatically
## validate chalk config files.
##
## :Author: John Viega (john@crashoverride.com)
## :Copyright: 2023, Crash Override, Inc.


default_key_priority := 4611686018427387904  # 2^62.

# These are the valid command-line commands.
valid_chalk_cmds     := ["help", "insert", "extract", "delete", "defaults",
                         "load", "dump", "docker", "version", "env", "exec",
		         #% REWRITE ,$ ]
                         "profile", "setup",
			 #% INTERNAL
			 "helpdump"]
			 #% END
all_cmds_that_insert := ["insert", "build", "load", "setup"]

# Beyond valid chalk commands, these can generate reports.
other_report_ops     := ["build", "push", "heartbeat"]
tool_types           := ["sbom", "sast"]
valid_log_levels     := ["verbose", "trace", "info", "warn", "error", "none"]
key_types            := ["Chalk-time Host", "Chalk-time Artifact",
                         "Run-time Artifact", "Run-time Host"]
known_sink_filters   := ["log_level", "log_prefix", "pretty_json",
                         "fix_new_line", "add_topic", "wrap"]

# This is the enum for key types.   See 'key' object documentation below
# for more details.
#
enum ChalkTimeHost, ChalkTimeArtifact, RunTimeArtifact, RunTimeHost

# The four types of metadata keys are collected at different points in
# a chalk run, thus there are different callbacks a plugin much
# implement for each type of key.
#
# The plugins must declare the keys they delcare for
# each phase, so that the system can decide whether to even to
# load the plugin and call into it.
#
# The four types (from the four constants above) are:

# 1) ChalkTimeHost: Collect before we start chalking artifacts.
#                   
#                   This could include things that *might* be different on
#                   a per-artifact basis, but where our collection isn't yet
#                   good enough.
#
# 2) ChalkTimeArtifact: While we are processing artifacts, before adding
#                       the chalk mark.  

# 3)RunTimeArtifact: Always collected after an operation on an artifact,
#                    but before processing the next artifact.
#                    These *cannot* include Chalk-time keys.

# 4) RunTimeHost:   Collected after all artifacts are processed.
#                   Nothing here can be chalkable.
# These are just used internally as part of validation routines.

# CC == collection context, meaning where are we in the collection process.
# pre-run is when chalk-time host keys are collected,
# artifact collection is chalk-time artifact keys are collected,
# post-chalk is after an artifact has been processed
# post-run is after ALL artifacts have been processed

enum CCPreRun, CCArtifact, CCPostChalk, CCPostRun

# PT == Profile Type.
enum PTChalk, PTArtifact, PTHost, PTChalkTimeArtifact

# Make these available through stacks.  Enums are automatically
# avalable through stacks.
export default_key_priority, valid_chalk_cmds, all_cmds_that_insert
export known_sink_filters, other_report_ops

object key {
  # TODO: no callbacks or value fields when system is set on the keyspec.
  user_def_ok:   false
  gen_fieldname: "keys"
  gen_typename:  "KeyConfig"
  gen_setters:   false
  doc:           """
Specifies profile-specific properties for specific metadata keys.
Currently, there is only a 'report' field.

See 'chalk help keyspec' for an overview of how keys are specified,
'chalk help keys' for lists of metadata keys, or 'chalk help key KEYNAME'
for all information on a single key.
"""

  field report {
    type:     bool
    default:  true
    doc: """
Whether to include the specific key when the profile reports.

Note that, when you explicitly enable keys in a profile, any reporting
context using the profile must be valid for the keys set to 'report',
or else you will get an error.
"""
  }

  field order {
    type:     int
    require:  false
    doc:      """
Used to set the reporting order. If not provided, this will inherit
the normalization order from the associated keyspec.
"""
  }
}

object profile {
  user_def_ok:   false
  gen_fieldname: "profiles"
  gen_typename:  "Profile"
  gen_setters:   false

  field enabled {
    type:    bool
    default: true
    doc: """
Whether to use this profile. If it's disabled, it won't be used, even
if it's part of the current 'outspec'.  If a command can't report at
all (or can't chalk if an insert command), then chalk will not run.
"""
  }

  field doc {
    type:     string
    require:  false
    hidden:   true
  }

  allow key {}
  # This doc string is shown w/ help profile props
  doc: """
Each profile can have a number of "key" objects, the name of which should be a key.

The sole variable in a "key" object is "report", which is a boolean, indicating whether this profile should report on that key.

See 'chalk help keys' for more on individual keys.
"""
}

object tool {
   user_def_ok:   true
   gen_fieldname: "tools"
   gen_typename:  "ToolInfo"
   gen_setters:   false
   doc:           """

Tool sections allow you to automatically run external tools for
collecting metadata, for tool types that are known to chalk (This
doesn't preclude chalk from providing its own collection for these
keys in the future).

Some of these tools are pre-configured with chalk, but you can also
add your own tool sections, as long as you provide appropriate
information in the config file via con4m callbacks.

Current tool classes are "sbom" and "sast":

- "sbom" tools collect SBOM information on a per-artifact basis.
- "sast" tools perform static analysis, and give a SARIF-formatted output.

You can run multiple tools of the same kind. Each tool metadata key
returns a key-value pair, the keys representing tools as named in the
configuration file, and the value being the output in string format:

- SBOMs are expected be returned in CycloneDX format. The appropriate
        metadata key these will be reported through, is 'SBOM'.
- SAST output is expected to be returned in the SARIF format.

Note that chalk itself is not currently validating the format, but the
tools that ship with chalk (see "chalk defaults tools") currently
respect it (with appropriate escaping to marshal them into a JSON
string).

Additionally, it is possible to use external code-signing tools. By
default, chalk will use gpg if present, signing if the GPG_SIGNING_KEY
variable is set.  However, this is implemented via a con4m callback
that you may override.  This is not configured as part of 'tool'
sections.
"""
   field enabled {
     type:     bool
     default:  true
     doc:      "If this is set to false, the tool is never run."
   }

   field kind {
     type:       string
     require:    true
     choice:     tool_types
     write_lock: true
     doc:        "Specifies which kind of tool this is."
   }

   field runs_once {
     type:       bool
     default:    true
     write_lock: true
     doc:        "Does the tool implementation get invoked per-artifact or per-run?"
   }

   field priority {
     type:     int
     default:  50
     range:    (0, high())
     doc:      """
Prioritizes the order tools get called in. Lower numbers are higher priorities.
"""
   }

   field stop_on_success {
     type:     bool
     default:  false
     doc:      "Use this if you only want to run one tool, but want to " +
               "try a number of tools until one is found.  Specifically, " +
	       "If a tool sets this and runs successfully, no tool of the " +
	       "same kind that has a lower priority will run at all."
   }

   field get_tool_location {
     type:     func (string) -> string
     require:  true
     doc:      """
A callback used when implementing tools. This must return the path to
the tool, after searching for it.  The argument will pass any
operation-specific context if a tool might be called with different
contexts that might require different actual tools.  Specifically, the
path will be passed for all existing tool types.

There is a generic implementation of this called `do_which` that can
be used directly, or can be called if you want to do something fancier.
"""

   }

   field attempt_install {
     type:     func (string) -> bool
     require:  true
     doc:      """

A callback used when implementing tools.  You must implement this for
any new tool you add, even if you have no intention of ever attempting
an actual installation (in which case, it can simply return false).
get_tool_location() will be called again if the install is reported
to be successful.

See the con4m documentation for functions that can help, such as file
access, execution, etc.
"""
   }

   field get_command_args {
     type:     func (string) -> string
     require:  true
     doc:      """
Given the artifact path and an argument determined based on the
metadata-key, return the command-line (argv minus program name) that
we should run. This is passed to the system shell; Note that we do not
run w/ privs even if chalk is setuid()
"""
   }

   field produce_keys {
     # exit code, output
     type:     func (string, int) -> dict[string, string]
     require:  true
     doc:      """
Given the exit code and output from running the command line, return
the appropriate value.  You're expected to return the chalk key name
from the keyspec object, and the value.  For instance, when
implementing an SBOM tool, return {"SBOM" : "..."}, even though this
will get lifted to {"SBOM" : {"yourtool" : "..."}} once multiple tools
are processed.

Note that if tool execution fails, or there is no output, you can
return no value.  If you want to output an error, warning, or
informational statement, you can add the key "error", "warn", or
"info" (must be lower case to distinguish from metadata keys).

If the "error" key is present, this will also be taken as a tool
failure, and no other keys will be checked.
"""
   }

  field doc {
    type:     string
    require:  false
    hidden:   true
  }
}

object keyspec {
  user_def_ok:   false
  gen_fieldname: "keyspecs"
  gen_typename:  "KeySpec"
  gen_setters:   false
  doc:           """
The keyspec section is where you define critical metadata about chalk
keys.  The spec can even specify the value of the key.

There are four different kinds of keys:

1) Chalk-Time Host: Keys collected at chalk time only, that are
                    per-host data. They're collected before chalking
                    any software artifacts.

2) Chalk-Time Artifact: Keys collected while chalking an artifact,
                        before performing the chalk operation.
                        Plugins can provide these early, if the value is
                        destined to be the same for every artifact, unless
                        the keyspec field "never_early" is true.

3) Run-time Artifact:   Per-artifact keys that are *not* available at chalk
                        time. They can generally be collected for any
                        operation, and are collected right after any
                        artifact is processed.

4) Run-Time Host:      Per-run keys that are not available for chalking,
                       and also are never expected to be artifact-specific.
                       They're collected after any artifacts are processed. 

For clarity as to what is chalkable, all Chalk-time keys can be added
to chalk marks. Their names will *never* start with a leading
underscore.

Run-time keys will *always* start with a leading underscore.

The base chalk spec defines many metadata keys, but you may also
define your own, by adding your own keyspec sections, as long as they
start with either 'X-' (for keys that can appear in a chalk mark), or
'_X-' (for keys that are unchalkable metadata, often per-run keys).

Some fields in keyspecs will be overridable; for instance, you can set
default values or change output order priorities for many
keys. However, there will be some keys where the implementation must
be handled by the system to be conformant, or where there are
technical considerations the output should mirror (for instance, the
SIGNATURE should really go after everything being signed).

Generally, when reviewing specific keyspecs, when they have fields
with "write_lock" set, those fields will not be overwritable.

See "chalk help keys" or "chalk help key KEY_NAME" for specific key type
info.
"""

  field required_in_chalk_mark {
    # Required fields apply only to what must go into a chalk mark.
    type:        bool
    default:     false
    write_lock:  true
    doc:         """
This field will only be true for keys that MUST be in a bare-minimum
chalk mark (even if the chalk mark is not inserted directly into the
artifact; so called 'virtual' chalk marks are expected to be put
elsewhere, but must still contain at least required keys.
"""
  }

  field required_in_self_mark {
    type:        bool
    default:     false
    write_lock:  true
    doc:         """
This field is true in keys that must be set when self-chalking.
"""  
  }

  field kind {
    type:        int
    require:     true
    write_lock:  true
    range:       (ChalkTimeHost, RunTimeHost)
    doc: """
Specifies which of the four chalk key types applies for this key. While this
is an integer, there's an enumeration defined you can use:

ChalkTimeHost, ChalkTimeArtifact, RunTimeArtifact, RunTimeHost
"""
  }

  field never_early {
    type:        bool
    default:     false
    write_lock:  true
    validator:   func never_early_check
    doc: """
True for keys of kind "ChalkTimeArtifact" where it would never make
sense for a plugin to assign the same value to all keys.  For
instance, the repo URI *could* be different per-artifact, but it's
perfectly reasonable for a plugin to not check the repo on each
artifact, and assume the one in the CWD.

If metadata whose keys have 'never_early' set to 'false' are
placed in the host report but not the artifact report, then
they will only show up in the host report if the plugins
report them pre-chalking, or if every single chalk has the
same value.  Otherwise, the value will be skipped.

If you add to both the host and artifact report, host will
be preferred, but it will still show up per-artifact if
appropriate.
"""
  }

  field type {
    type:       typespec
    require:    true
    write_lock: true
    doc: """
The data type associated with the key. Generally, all keys should map
clearly to types supported by JSON.
"""
  }

  field standard {
    type:        bool
    require:     false
    stack_limit: 0
    hidden:      true
    doc:         """
Standard keys are those that are part of either the Chalk spec, or
the chalk internals (keys that start with $).  Non-standard keys
must meet the naming rules for user-defined keys.
"""
  }

  field system {
    type:       bool
    default:    false
    write_lock: true
    doc:        """
System keys may not be user-set, other than via the system plugin, or other
parts of the system implementation not part of the plugin system.  These keys
can never be redefined directly (though some may be indirectly set in codecs
by the methods they implement).
"""
  }

  field conf_as_system {
    type:        bool
    default:     false
    stack_limit: 0
    hidden:      true
    doc:         """
True if the value of a system key can actually be set by the conffile value
or callback field.  This is really an internal thing.
"""
  }

  field codec {
    type:       bool
    default:    false
    write_lock: true
    doc: "Codec keys may only be provided by codecs (and MUST be provided)."
  }

  field value {
    type:       "type"
    require:    false
    doc:        """
If nothing overrides, the conffile plugin will add these in.  Cannot appear
with a 'callback' field.
"""

  }

  field callback {
    type:       func (string) -> `x
    require:    false
    validator:  func key_callback_check
    doc:        """
If nothing overrides, the conffile plugin will call this for a value.  Cannot
appear with a 'value' field.
"""
  }

  field since {
    type:       string
    require:    false
    write_lock: true
    doc: "Version of the standard in which this key first appeared."
  }

  field normalized_order {
    type:        int
    default:     default_key_priority
    range:       (0, high())
    doc: """
The normalization order used for signing and hashing metadata.
This only works for built-in keys; everything else is given the same
priority and should be sorted alphabetically.
"""
  }

  field apply_substitutions {
    type:        bool
    default:     false
    write_lock:  true
    doc: """
For variables where this is true, the system will, immediately before signing
and computing a metadata hash, apply any appropriate variable substitutions.
Currently supported variable substitutions are:

{chalk_id} -> value of CHALK_ID
{now}      -> value of TIMESTAMP
{path}     -> value of PATH_WHEN_CHALKED
{hash}     -> value of HASH
{tenant}   -> value of TENANT_ID
{random}   -> value of CHALK_RAND

Note that these substitutions currently only are applied to chalkable
keys, and those keys must not have been lifed into the host context by
whatever plugin collected them.
"""
  }

  field doc {
    type:     string
    require:  false
    hidden:   true
  }

  exclusions {
    value: "callback"
  }
}

object plugin {
  gen_fieldname: "plugins"
  gen_typename:  "PluginSpec"
  user_def_ok:   false
  gen_setters:   false

  field priority {
    type:     int
    default:  50
    range:    (0, high())
    doc: """
Plugins are called in priority order (lower numbers are higher
priority).  You can redefine this field for most of the builtin
plugins, with the exception of the system plugins that wrap the
process (particularly to ensure that all data is available both for
other plugins that might need it, and for metadata signing, which must
therefore come last).
"""
  }

  field ignore {
    type:    list[string]
    default: []
    doc:     "Keys from this plugin the user wishes to ignore."
  }

  field codec {
    type:       bool
    default:    false
    write_lock: true
    doc:        "This key must be set for all codecs."
  }

  field pre_run_keys {
    type:       list[string]
    default:    []
    write_lock: true
    validator:  func pre_run_key_check
    doc: "List of keys this plugin provides before our artifact collection."
  }

field artifact_keys {
    type:       list[string]
    default:    []
    write_lock: true
    validator:  func chalk_key_check
    doc:        """
List of keys this plugin provides during artifact collection.
If they are chalkable keys, they must only be provided during
chalk operations.  Non-chalkable per-artifact keys can always
be provided here if appropriate.
"""
  }

  field post_chalk_keys {
    type:       list[string]
    default:    []
    write_lock: true
    validator:  func post_chalk_key_check
    doc:        """
List of keys this plugin provides after an artifact is chalked,
before the next artifact is processed.
"""
  }

  field post_run_keys {
    type:       list[string]
    default:    []
    write_lock: true
    validator:  func post_run_key_check
    doc:        "List of keys this plugin provides after a run completes."
  }

  field enabled {
    type:    bool
    default: true
    doc:     "Setting this field completely disables a plugin."
  }

  field overrides {
    type:      list[string]
    default:   []
    validator: func override_key_check
    doc:       """
This field can be used to specify keys where this plugin's value
should be taken, even if a value has already been collected for
the key.  This is invalid for system keys.
"""
  }

  field doc {
    type:    string
    require: false
    hidden:  true
  }
}

object sink {
  gen_fieldname: "sinks"
  gen_typename:  "SinkSpec"
  gen_setters:   false
  user_def_ok:   true
  validator:     func sink_object_check
  doc:           """
This object type is needed to add new data sinks to chalk.  Note that
sinks configurations are loaded after all config files are run, so if
you want to add a sink_config object to configure one of these sinks,
and then you want to use that configuration in I/O immediately, you
need to call load_sink_configs() explicitly.

When adding a sink to Chalk, the fields you add should be the fields
you may take as parameters in a sink_config. All parameters will be of
type 'string'. If the parameter is required, then set the value to
'true'.  If it is not required, then set the value to 'false', unless
you want to provide a default value, in which case, set the value as a
string.

For the moment, each 'sink' object is expected to tie to a sink
implementation loaded in chalk.
"""

  field doc {
    type:    string
    require: false
    hidden:  true
  }
}

object sink_config {
  gen_fieldname: "sinkConfs"
  gen_typename:  "SinkConfigObj"
  gen_setters:   false
  user_def_ok:   true
  validator:     func sink_config_check
  doc: """
Configure a sink, using the fields provided in that sink spec.
"""

  field enabled {
    type:    bool
    default: true
    doc: """
Set to false to leave in the config but disable it.
"""
  }

  field filters {
    type:    list[string]
    default: []
    validator: func sink_filter_check
    doc: """
Filters to install.  Valid options are:
{bold}log_level{reset} -- Used for reporting to the log sink, this completely filters out messages that aren't as 'important' as the current log level.  The default output configuration has this installed.
{bold}log_prefix{reset} -- Used to add the name of the log level to log messages.  This is added in the default log configuration.
{bold}pretty_json{reset} -- Assumes the input is JSON, and then formats it for human output, mainly adding newlines and a bit of indentation.
{bold}fix_new_line{reset} -- Add a newline to the end of any published message if it doesn't already have one.
{bold}add_topic{reset} -- Not used by default, but adds a header to any message noting the topic.
{bold}wrap{reset} -- Wrap text, taking the current terminal width into account.
"""
  }

  field sink {
    type:       string
    default:    ""  # Will cause this to get ignored.
    # Turning off, because attempts to copy the default config will generally
    # fail due to this, and it seems to lead to plenty of confusion that I do
    # not want.
    # write_lock: true
    doc: "The base sink; other attrs in this section are based on this value."
  }
}

object outconf {
  gen_fieldname: "outputConfigs"
  gen_typename:  "OutputConfig"
  gen_setters:   false
  user_def_ok:   false
  doc:           """
Binds profiles to commands.  The only valid object names for outconf sections
are the names of valid chalk commands.  There are default profiles with
reasonable defaults for every command.
"""

  field chalk {
    type:      string
    default:   ""
    validator: func outconf_chalk_check
    doc:       """
This profile is only allowed for commands that create chalk objects, and
governs what will be put into the chalk mark.
"""
  }

  field artifact_report {
    type:      string
    default:   ""
    validator: func outconf_artifact_check
    doc:       """
The named profile is used for when reporting on per-artifact any
information, so works with any command. If both this field and the
'invalid_chalk_report' field are defined, then this profile gets used
when the extracted chalk mark fully validates.  That DOES generally
require you to be using signatures, though at some point we may
optionally allow validation to be considered 'successful' only if the
integrity check passes, even if this makes marks forgable.
"""
  }

  field invalid_chalk_report {
    type:      string
    default:   ""
    validator: func outconf_invalid_chalk_check
    hidden:    true
    doc:       """
The named profile is used for reporting per-artifact, any time the
digital signature is fully validated. The general idea here is that,
if you like, you can minimize the amount of data you send back to a
server by only retrieving a minimal amount of data, and only send up
full chalks when chalks do not validate.

That could be useful when you've performed the chalk operation, so
validation helps ensure you already have the rest of the information
server-side.

However, there is currently no easy mechanism for checking to see if
you already know about this chalk mark. If it was chalked from some
other organization, but the validation check is passed, you will still
get this profile.

As a result, our preferred method for dealing with duplicate info is
to check the METADATA_ID server-side before insertion into any data
store.

However, if you choose to save on bandwidth, we recommend you pass
back enough identifying information (via non-chalk per-artifact keys),
that you can re-run chalk forcing a different profile (and ideally in
a way you fully automate).
"""
  }

  field host_report {
    type:      string
    default:   ""
    validator: func outconf_host_check
    doc:       """
The named profile is used to determine which host-level metadata keys
will be used in the report.  Note that, without this report enabling
the '_CHALKS' key, *NO* artifact-level information will be reported,
which generally makes managing chalk information harder, since the
artifact will, at the point of chalk, be the sole record of the mark.
"""
  }

  field doc {
    type:     string
    require:  false
    hidden:   true
  }
  doc: """
Specifies what reporting profiles to use for I/O on a per-command
basis. Only valid chalk commands are valid section names.
"""
}

object custom_report {
  gen_fieldname: "reportSpecs"
  gen_typename:  "ReportSpec"
  gen_setters:   false
  user_def_ok:   false
  doc:           """
The custom_report object allows you to create secondary reports for
whatever purpose.  The built-in 'audit' capability uses this (when
enabled) to store information about the configuration used when chalk
runs.

Similarly, it can be used for reporting summary statistics, for
instance, simply sending an empty message to mark when the executable
is run.

Or, you can use this to implement a second report with different data
fields that goes to a data lake for analysis, or to the local file
system as a failsafe if there are network connectivity problems.
"""

  field enabled {
    type:      bool
    default:   true
    doc:       """
For any custom report, this field must be set to 'true' for chalk to
run the report.

Even for the built-in audit report, if you override this field, the
audit report will not run, even if you've set the option to enable
auditing.

Custom reports never chalk; you must use the appropriate 'outconf'
report.
"""
}

  field sink_configs {
    type:      list[string]
    require:   true
    validator: func sink_list_check
    doc: """
A list of sink configurations that should be subscribed to this report.
Basically, this controls where your report will output.
"""
  }

  field artifact_report {
    type:       string
    default:    ""
    validator:  func custom_report_artifact_check
    doc:        """
The named profile is used for when reporting on per-artifact any
information. If both this field and the 'invalid_chalk_report' field
are defined, then this profile gets used when the extracted chalk mark
fully validates.  That DOES generally require you to be using
signatures, though at some point we may optionally allow validation to
be considered 'successful' only if the integrity check passes, even if
this makes marks forgable.
"""
  }

  field invalid_chalk_report {
    type:       string
    default:    ""
    validator:  func custom_report_artifact_check
    doc:        """
If provided, this is the profile used for non-validating chalks, instead of
the profile given in artifact_report.  See the 'outconf' field
'invalid_chalk_report' for considerations.
"""
  }

  field host_report {
    type:      string
    default:   ""
    validator: func custom_report_host_check
    doc:       """
The named profile is used to determine which host-level metadata keys
will be used in any report.  Note that, without this report enabling
the '_CHALKS' key, *NO* artifact-level information will be reported.
"""
  }

  field use_when {
    type:      list[string]
    default:   ["*"]
    validator: func use_when_check
    doc:       """
This field allows you to specify (without conditional logic in the
configuraiton file), the chalk commands that will trigger this report.
That is, if the current chalk command is not in this list, then the
report will NOT run.

If not specified, reports apply to any command that reports.
"""
  }

  field doc {
    type:     string
    require:  false
    hidden:   true
  }
}

singleton extract {
  gen_fieldname: "extractConfig"
  gen_typename: "ExtractConfig"
  gen_setters: false
  user_def_ok: false
  doc: """
Configuration specific to how `chalk exec` behaves.  
  """

  field ignore_unsigned_images {
    type:    bool
    default: false
    shortdoc: "Ignore unsigned images"
    doc: """
When running a scan of all images, if this is `true`, Chalk only will try to extract Chalk marks from locally stored images if the image has a Chalk signature added via cosign attestations.

By default we skip unsigned images, because the process (necessarily) involves downloading the container image.
"""    
  }

  field search_base_layers_for_marks {
    type:    bool
    default: false
    shortdoc: "Extract marks from containers"
    doc: """
When extracting from images when `ignore_unsigned_images = false`, Chalk will start by checking for a digital signature containing the Chalk mark in the repo, when available.

But if there's no signature, assuming `ignore_unsigned_images` is true, Chalk looks in the top layer of the file system.

When no Chalk can be found in either place, if this attribute is set to true, we'll look at the other layers in the image and report the `CHALK_ID` and `METADATA_ID` of the topmost layer with a mark, using the `_FOUND_BASE_MARK` key (the image itself is said to be unchalked; it's more about being able to use knowledge of a chalked base image).

Note that this does nothing unless `ignore_unsigned_images` is false.
"""    
  }
}

singleton docker {
  gen_fieldname: "dockerConfig"
  gen_typename:  "DockerConfig"
  gen_setters:   false
  user_def_ok:   false
  doc: """
Configuration specific to the `chalk docker` command.
"""
  allow getopts { }

  field wrap_entrypoint {
    type:    bool
    default: false
    shortdoc: "Automatically wrap entrypoints"
    doc:     """
When running the docker command, this option causes `chalk docker build` to
modify containers to, on entry, use `chalk exec` to spawn your process.

Note that, by default, Chalk will use its own binary for the wrapping, unless
it sees an arch flag and determines that this is the wrong binary.

In such a case, you should have a binary available for the
architecture you are uilding for to copy in, and then specify it with
`chalk_wrap_exe`

Note that *either* we need to be able to copy the chalk binary into
the context directory before invoking Docker, or you need to be on a
version of Docker that accepts `--build-context`.

The configuration of the chalk process inside the container will be
inherited from the binary doing the chalking.

If, when wrapping, your chalk binary is using an external
configuration file, that file will NOT get used inside the
container. The wrapped binary currently only uses the embedded
configuration present in the binary in the time of the wrapping.
"""
  }

  field arch_binary_locations {
    type:     dict[string, string]
    require:  false
    shortdoc: "Locations for entrypoint binaries"
    doc: """
Whenever Chalk does automatic entry-point wrapping, it uses its own
binary and its own `exec` config to move into the entry
point. However, if the container being built is of a different
architecture, it cannot do that.

If this field is set, it maps docker architecture strings to locations
where the configured Chalk binary lives for the platform. Currently,
this only accepts local file system paths, so the binary must be
local.

If there isn't an architecture match, and no binary can be found per
this field,

Keys are expected in "Os/Architecture/Variant" form, eg:
"linux/arm64", "linux/amd64", "linux/arm/v7" etc.

Note that Chalk itself is only targeted for a subset of the platforms
that officially support Docker, specifically Linux on arm64 and amd64
(no Windows yet). If an entrypoint wrapping is performed on any
architecture not in this set (bravo for getting Chalk to build!), it
will still refuse to copy itself in, except via this configuration
field.
"""    
  }

  field label_prefix {
    type:    string
    default: "run.crashoverride."
    shortdoc: "Prefix for added labels"
    validator: func label_prefix_check
    doc: """
When docker labels are used, they are supposed to have a reverse-DNS
prefix for the organization that added them. You generally should add
your own organization here.
"""
  }

  field label_profile {
    type:    string
    default: "chalk_labels"
    validator: func label_profile_check
    shortdoc: "Auto-added label profile"
    doc: """
This profile guides what labels will be automatically added to docker
images when we successfully chalk them. The only allowed keys are
Chalk-time keys. And, if the metadata is not available, then no key
will be added.

For instance, the `HASH` key cannot currently appear in docker chalks,
because it is not available for chalk-time, so will not appear as
a label.  But, you can add `METADATA_ID`, `CHALK_ID`, etc. or anything
else that is collectable before the build.
"""
  }

  field custom_labels {
    type: dict[string, string]
    require: false
    validator: func custom_labels_check
    shortdoc: "Custom labels"
    doc: """
Any labels added here will be added as a `LABEL` line to the chalked
container.  This will add `label_prefix` before the keys, and will not
add if the key is not an alphanumeric value.
"""
  }

  field report_unwrapped_commands {
    type:    bool
    default: false
    shortdoc: "Report on unwrapped commands"
    doc: """
If true, host reports will be generated for docker commands we do not wrap.
By default, we do not report.  If you set this to 'true', it's helpful to
have `_ARGV` in your report, to get more telemetry.

Note that failed chalk attempts get published to the 'fail' topic, and there
are no default output sinks subscribed to this topic.
"""
  }

  field report_empty_fields {
    type:     bool
    default:  false
    shortdoc: "Report on empty docker metadata"
    doc: """
Docker's internal reporting often gives results that are empty when
not set.  If this is on, such fields are elided on reporting.

"""
  }

  field additional_env_vars {
    type: dict[string, string]
    default: { }
    shortdoc: "Additional container environment variables"
    doc: """
When doing non-virtual chalking of a container, this will
automatically add an `ENV` statement to the *end* of the Dockerfile
passed to the final build. Keys may only have letters, numbers and
underscores (and cannot start with a number); the values are always
quoted per JSON rules.

If you want to add chalk-time metadata, have the value be the chalk
key, prefixed with an @.  For instance:

```
{ "ARTIFACT_IDENTIFIER" : "@CHALK_ID" }
```

will add something to the dockerfile like:

```
ENV ARTIFACT_IDENTIFIER="X6VRPZ-C828-KDNS-QDXRT0"
```
"""    
  }
}

singleton exec {
gen_fieldname: "execConfig"
gen_typename:  "ExecConfig"
gen_setters:   false
user_def_ok:   false
doc: """
Configuration information for when running the chalk 'exec' command.

The 'exec' command works by forking, and having the child do the chalk reporting.  The parent becomes whatever process you configure in this section.
"""

  field command_name {
    type:     string
    default:  ""
    shortdoc: "Exec: command name"
    doc: """
This is the name of the program to run, when running the 'exec' command.  This command will end up being the process you directly spawned; chalking happens in a fforked-off process.

You must set a value for this variable or pass the --exec-command-name flag to be able to use the 'exec' command.
"""
  }

  field search_path {
    type:     list[string]
    default:  []
    shortdoc: "Exec: extra search directories"
    doc: """
While the 'exec' command does, by default, search the PATH environment variable looking for what you want to run, this array gets searched first, so if you know where the executable should be, or if you're worried that PATH won't be set, you can put it here.

Also, you can turn off use of PATH via exec.use_path, in which case this becomes the sole search path.
"""
  }

  field chalk_as_parent {
    type:    bool
    default: false
    shortdoc: "Chalk as parent process"
    doc: """
When running the 'exec' command, this flag sets up Chalk to be the parent process.  The Chalk default is to be the child process.  However, when execing a short-lived process running inside a container, there is no way for Chalk to keep itself alive as the child once the parent dies, unless the parent had previously intervened.

As a result, when this is set to true, during an 'exec' operation, Chalk forks and takes the parent role, and the child process execs.  Chalk does its work, then calls waitpid() on the process, and returns whatever exit value the exec'd process returned.

This can be set at the command-line with --chalk-as-parent (aka --pg-13)
"""
  }

  field reporting_probability {
    type: int
    default: 100
    validator: func validate_probability
    shortdoc: "Exec reporting probability"
    doc: """
When doing a 'chalk exec', this controls the probability associated with whether we actually send a report, instead of exec-only.  This is intended for high-volume, short-lifetime workloads that only want to sample.  It must be an integer percentage.
"""
  }

  field default_args {
  type:     list[string]
  default:  []
  shortdoc: "Exec: Default arguments"
  doc: """
When running chalk in 'exec' mode, these are the arguments that should, by default, be passed to the spawned process.

If command-line arguments are provided, you have three options:

1. Always send these arguments, and have any additional arguments be appeneded to these arguments.  For these semantics, set append_command_line_args to true.
2. Have the command line arguments REPLACE these arguments.  For these semantics, set override_ok to true.  This is chalk's default behavior, absent of any other configuration.
3. Disallow any command-line argument passing.  For this behavior, set both of the above variables to 'false'.

Setting both to 'true' at the same time is not semantically valid, and will give you an error message; nothing will run.
"""
  }

  field append_command_line_args {
    type:      bool
    default:   false
    shortdoc: "Exec: append command-line args"
    doc: """
When true, any command-line arguments will be appeneded to exec.default_args instead of replacing them.
"""
  }

  field override_ok {
    type:     bool
    default:  true
    validator: func exec_arg_semantics_check
    shortdoc: "Exec: override default_args"
    doc: """
When true, if the 'chalk exec' command has any arguments passed, they will replace any arguments provided in default_args. 
"""
  }

  field use_path {
    type:    bool
    default: true
    shortdoc: "Exec: use PATH"
    doc: """
When this is true, the PATH environment variable will be searched for your executable (skipping this executable, in case you want to rename it for convenience).

If it is NOT true, set exec.searchpath to provide any locations Chalk should check for the executable to exec.
"""
  }

  field heartbeat {
    type:    bool
    default: false
    shortdoc: "Report heartbeats"
    doc: """
When this is true, Chalk will, after initial reporting, connect
periodically to post "heartbeat" reports. The beacon report frequency is
controlled by the `heartbeat_rate` field.
"""    
  }

  field heartbeat_rate {
    type:    Duration
    default: <<20 seconds>>
    shortdoc: "Heartbeat rate"
    doc: """
When `heartbeat` is true, after any report, chalk will sleep the specified
amount of time before providing another heartbeat report.

Note that, when Chalk is running in a container, the container may
exit before any particular report completes, and can even kill one in
the middle of it posting.

When running outside a container, or if inside a container, but
running as a parent process, the heartbeat process will exit after a
final report, if the monitored process has exited.
"""    
  }
}

singleton env_config {
  gen_fieldname: "envConfig"
  gen_typename:  "EnvConfig"
  gen_setters:   false
  user_def_ok:   false
  doc: """
Internal configuration information gathering runtime environment
information when running with the 'env' command, which is similar to
the exec command, but where the exec command executes a subprocess
that is the focus of reporting, env just reports on the host
environment, and optionally any processes that you're interested.

If there is a /chalk.json file, this will assume it is in a container,
and report on pid 1.
"""


  field process_report_patterns {
    type:    list[string]
    default: []
    shortdoc: "Processes to report on"
    doc: """
If passed, Chalk will match processes by name to report on, accepting
regular expression matches. It looks up processes via the system
facilities for process listing, and does try to look up the binary
from that, if it has access.
"""
  }
}

singleton source_marks {
  gen_fieldname: "srcConfig"
  gen_typename:  "SrcConfig"
  gen_setters:   false
  user_def_ok:   false
  
  doc: """
This controls whether and how source-based artifacts are marked.

Generally, the marking occurs by sticking the mark in a comment.

Currently, the intent for source marking is to mark content that will
be shipped and run in source code form. While you *can* mark every
source file, we don't really encourage it. For that reason, by
default, our database only contains reasonably well used scripting
languages, and is configured to only mark things with unix Shebangs
(extraction doesn't consider the shebang).

We also definitely do **not** recommend marking code while it is in a
repository. Git does that job well, and no tooling exists to help
recalculate every time you make an edit.

Ideally, you might wish to mark both a file and any
dependencies. Currently, with the exception of container images /
containers, Chalk doesn't handle that, as it's significantly difficult
to be particularly precise about what is part of the artifact and what
isn't.
"""

  field only_mark_shebangs {
    type:    bool
    default: true
    shortdoc: "Marking requires #! in script"
    doc: """
If this is true, we will only mark files that have a shebang line
(i.e., the first line starts with `#!`).

This is useful in many scripting languages, as the main entry point is
often made executable and given a shebang, whereas supporting files
are not.

Currently, Chalk has no native support to try to determine which files
the language is likely to deem an entry point. We do not attempt to
understand any package/module system, etc.

If you'd like to do that, you can add a custom callback.

Extraction does not check this.  It will attempt to extract from any
file that appears to be valid utf when looking at the first 256 bytes,
unless you provide a custom callback.
"""
}

  field only_mark_when_execute_set {
    type:    bool
    default: false
    shortdoc: "Marking requires +x"
    doc: """
    
When this is true, Chalk will not attempt to mark source code *unless*
the executable bit is set. However, the execute bit can get added later;
it's a trade-off!

Extraction does not check this.  It will attempt to extract from any
file that appears to be valid utf when looking at the first 256 bytes,
unless you provide a custom callback.
"""    
  }

  field text_only_extensions {
    type: list[string]
    default: ["json", "jsonl", "txt", "text", "md", "docx"]
    shortdoc: "Extensions that should be ignored, even if they have something that looks like a chalk mark"
    doc: """
Chalk extraction generally assumes that if it finds a chalk mark in a
text file, then it should report it. But, that isn't true for
documentation!

So for all operations, we assume the extensions in this list can *never*
be source code.
"""    
 }
  
  field custom_logic {
    type:    func (string, string, string, bool, bool) -> bool
    require: false
    shortdoc: "A callback for custom logic."
    doc: """
If you'd like to have fine-grained control over what source gets
marked, you can do so by setting a callback.

Your callback will *not* supercede `shebangs_when_no_extension_match`
and `only_mark_when_execute_is_set`. Your callback will only get run
if those checks would lead to the file otherwise being marked.

The callback receives the following parameters:

1. The (resolved) file name for the file being considered.
2. The detected language (see below).
3. The file extension (so you don't have to carve it out of the file name).
4. A boolean indicating whether there was a shebang line (if
   `only_mark_shebangs` is on, this will always be true).
5. A boolean indicating whether the execute bit is set on the file system.
   This will always be true if `only_mark_when_execute_set` is true.

Language detection prefers the shebang line, if it's captured. The
language name will be matched with the following rules:

- We look at the first item after the #!, which will either be a full path or
  an exe name (where the path is searched).
- Any directory component is stripped.
- If the value is the word `env` then we instead look at the first non-flag
  item (again, stripping any directory component, even though generally
  we wouldn't expect to see any).
- Any trailing sequence of numbers and dots are removed.

Therefore, all of these will normalize the same way:

#! python
#! python3
#! /bin/env python
#! /bin/env python3.3.1

If chalk does not recognize the language, and your logic says to mark,
it will proceed to mark it, assuming that '#' is the comment character.
Alternatively, you can add the language to our database.

If there was no shebang line, or we did not look at the shebang line,
then we consult `source_marks.extensions_to_languages_map`.

If that turns up nothing, or if there is no extension, then we look at
the executable bit. If it's set, then we check to see if the file
seems to be valid utf-8, by looking at the first 256 bytes. If it is,
then we assume `sh` as the language.

Otherwise, we will assume the file is *not* an executable.

This also means that we might use odd language names, like 'node',
since it's the thing we're likely to see in a shebang line.
"""
  }

  field language_to_comment_map {
    type: dict[string, string]
    shortdoc: "Lang runtimes to comment sequence"
    doc: "Maps binary names for lang runtimes to their comment type"    
    default: {
      "sh"              : "#",
      "csh"             : "#",
      "tcsh"            : "#",
      "ksh"             : "#",
      "zsh"             : "#",
      "terraform"       : "//",
      "node"            : "//",
      "php"             : "//",
      "perl"            : "#",
      "python"          : "#",
      "ruby"            : "#",
      "expect"          : "#",
      "tcl"             : "#",
      "ack"             : "#",
      "awk"             : "#"
    }
  }
  
  field extensions_to_languages_map {
    type: dict[string, string]
    shortdoc: "File extensions to runtime binary"
    doc: "Maps file extensions to the binary names for lang runtimes"
    default: {
      "sh"              : "sh",
      "csh"             : "csh",
      "tcsh"            : "tcsh",
      "ksh"             : "ksh",
      "zsh"             : "zsh",
      "hcl"             : "terraform",
      "nomad"           : "terraform",
      "tf"              : "terraform",
      "_js"             : "node",
      "bones"           : "node",
      "cjs"             : "node",
      "es6"             : "node",
      "jake"            : "node",
      "jakefile"        : "node",
      "js"              : "node",
      "jsb"             : "node",
      "jscad"           : "node",
      "jsfl"            : "node",
      "jsm"             : "node",
      "jss"             : "node",
      "mjs"             : "node",
      "njs"             : "node",
      "pac"             : "node",
      "sjs"             : "node",
      "ssjs"            : "node",
      "xsjs"            : "node",
      "xsjslib"         : "node",
      "aw"              : "php",
      "ctp"             : "php",
      "phakefile"       : "php",
      "php"             : "php",
      "php3"            : "php",
      "php4"            : "php",
      "php5"            : "php",
      "php_cs"          : "php",
      "dist"            : "php",
      "phps"            : "php",
      "phpt"            : "php",
      "phtml"           : "php",
      "ack"             : "perl",
      "al"              : "perl",
      "cpanfile"        : "perl",
      "pl"              : "perl",
      "perl"            : "perl",
      "ph"              : "perl",
      "plh"             : "perl",
      "plx"             : "perl",
      "pm"              : "perl",
      "psgi"            : "perl",
      "rexfile"         : "perl",
      "buck"            : "python",
      "bazel"           : "python",
      "gclient"         : "python",
      "gyp"             : "python",
      "gypi"            : "python",
      "lmi"             : "python",
      "py"              : "python",
      "py3"             : "python",
      "pyde"            : "python",
      "pyi"             : "python",
      "pyp"             : "python",
      "pyt"             : "python",
      "pyw"             : "python",
      "sconscript"      : "python",
      "sconstruct"      : "python",
      "snakefile"       : "python",
      "tac"             : "python",
      "workspace"       : "python",
      "wscript"         : "python",
      "wsgi"            : "python",
      "xpy"             : "python",
      "appraisals"      : "ruby",
      "berksfile"       : "ruby",
      "brewfile"        : "ruby",
      "builder"         : "ruby",
      "buildfile"       : "ruby",
      "capfile"         : "ruby",
      "dangerfile"      : "ruby",
      "deliverfile"     : "ruby",
      "eye"             : "ruby",
      "fastfile"        : "ruby",
      "gemfile"         : "ruby",
      "gemfile.lock"    : "ruby",
      "gemspec"         : "ruby",
      "god"             : "ruby",
      "guardfile"       : "ruby",
      "irbrc"           : "ruby",
      "jarfile"         : "ruby",
      "jbuilder"        : "ruby",
      "mavenfile"       : "ruby",
      "mspec"           : "ruby",
      "podfile"         : "ruby",
      "podspec"         : "ruby",
      "pryrc"           : "ruby",
      "puppetfile"      : "ruby",
      "rabl"            : "ruby",
      "rake"            : "ruby",
      "rb"              : "ruby",
      "rbuild"          : "ruby",
      "rbw"             : "ruby",
      "rbx"             : "ruby",
      "ru"              : "ruby",
      "snapfile"        : "ruby",
      "thor"            : "ruby",
      "thorfile"        : "ruby",
      "vagrantfile"     : "ruby",
      "watchr"          : "ruby",
      "tcl"             : "tcl",
      "itk"             : "tcl",
      "tk"              : "tcl",
      "awk"             : "awk",
      "gawk"            : "gawk",
      "mawk"            : "mawk",
      "nawk"            : "nawk"
    }
    doc: """
"""    
  }
}

root {
  prologue: """
# This file is auto-generated as part of the chalk build.
# Please do NOT edit it. Edit the specification file from
# which it was generated instead: src/configs/chalk.c42spec
# That will trigger a rebuild.

"""
  gen_typename: "ChalkConfig"
  gen_setters:  false
  user_def_ok:  false

  allow keyspec       { }
  allow plugin        { }
  allow sink          { }
  allow sink_config   { }
  allow profile       { }
  allow outconf       { }
  allow custom_report { }
  allow tool          { }
  allow extract       { }
  allow docker        { }
  allow exec          { }
  allow env_config    { }
  allow source_marks  { }

  field config_path {
    type:       list[string]
    default:    ["/etc/chalk/", "/etc/", ".", "~/.config/chalk", "~"]
    write_lock: true
    doc:        "The path to search for an external configuration file."
    shortdoc:   "Configuration Path"
  }

  field config_filename {
    type:       string
    default:    "chalk.conf"
    write_lock: true
    doc:        "The file name to look for when searching for a file"
    shortdoc:   "Configuration File Name"
  }

  field valid_chalk_command_names {
    type:       list[string]
    default:    all_cmds_that_insert
    write_lock: true
    hidden:     true
    doc:        "Expose command names used for insertion to the implementation"
  }

  field valid_chalk_commands {
    type:       list[string]
    default:    valid_chalk_cmds
    write_lock: true
    hidden:     true
    doc:        "Expose the full list of command names to the implementation"
  }

  field ignore_when_normalizing {
    type:       list[string]
    default:    ["MAGIC", "METADATA_HASH", "METADATA_ID", "SIGNING", "SIGNATURE",
                 "EMBEDDED_CHALK"]
    write_lock: true
    hidden:     true
    doc:        """
This is a list of fields that are chalkable, that will not ever be included in
normalization operations used for computing metadata hashes and signatures.
"""
  }

  field default_command {
    type:       string
    require:    false
    write_lock: false
    validator:  func default_command_check
    shortdoc:   "Default Command (when not provided)"
    doc:        """
If no top-level command is passed on the command line, this command is
assumed.  By default, if the config file does not resolve the ambiguity,
then chalk will produce a help message.
"""
  }

  field selected_command {
    type:       string
    default:    ""
    write_lock: false
    shortdoc:   "The command we just ran"
    doc:        """

Once the command line is fully parsed, this will get the value of the
selected command.  If the command is ambiguous, fill it in with the
value 'default_commmand'.

In that case, this field doesn't get set with a real value until after
all your configuration files run.  Instead, it will be an empty
string.
"""
  }

  field color {
    type:     bool
    require:  false
    shortdoc: "Show Colors"
    doc: """
Whether to output ANSI color. If this is not explicitly set, will respect
the presense of a NO_ANSI environment variable, but is otherwise on by default.
"""
  }

  field log_level {
    type:     string
    default:  "warn"
    choice:   valid_log_levels
    shortdoc: "Console Log Level"
    doc: """
Determines what kind of logging messages show to the console. To see
everything, use 'trace' or 'verbose' (they are aliases).
"""
  }

  field chalk_log_level {
    type:     string
    default:  "error"
    choice:   valid_log_levels
    shortdoc: "Reporting Log Level"
    doc:      """
Determines what kind of logging messages will be added to metadata via the
ERR_INFO or _ERR_INFO keys. During the chalk phase of chalking ops only,
per-object errors that are at least as severe as specified will be added to
the object's  ERR_INFO field.

Everything else will go to _ERR_INFO.
"""
  }

  # Chalk posts to 'virtual' topic instead of calling insert.
  field virtual_chalk {
    type:     bool
    default:  false
    shortdoc: "Virtual Chalk Mode"
    doc:      """
This option implements 'virtual' chalking, where the chalk mark is not
inserted into an artifact via codec. Instead, the chalk mark gets
published to the "virtual" topic, and it is the user's responsibility
to do something about it.  Or else, you could treat it as a dry-run mode.

By default, virtual chalk marks will get appended to {bold}"./virtual-chalk.json"{reset}, but you can use the output system to send them anywhere (this is setup in the default configuration file).
"""
  }

  field zip_extensions {
    type:       list[string]
    default:    ["zip", "jar", "war", "ear"]
    validator:  func zip_check
    hidden:     true
    doc:        "Extensions that we assume are in ZIP format for the zip codec"
  }

  field py_extensions {
    type:       list[string]
    default:    ["py", "pyw", "ipy"]
    validator:  func py_check
    hidden:     true
    doc:        "Extensions that we assume are Python source files for the python .py codec"
  }

    field pyc_extensions {
    type:       list[string]
    default:    ["pyc", "pyo", "pyd"]
    validator:  func pyc_check
    hidden:     true
    doc:        "Extensions that we assume are Python bytecode files for the python .pyc codec"
  }

  field con4m_pinpoint {
    type:    bool
    default: true
    hidden:  true
    doc:     """
When outputting errors in the config file, try to put a marker under the line
where the compiler found an error to show the exact location.
"""
  }

  field chalk_debug {
    type:    bool
    default: false
    hidden:  true
    doc:     "Show Nim stack traces, including for con4m errors."
  }

  field cache_fd_limit {
    type:    int
    default: 50
    range:   (0, high())
    hidden:  true
    doc:     """
We are caching file descriptors, because the original implementation would scan
everything before chalking anything. This is no longer done, so this code is no
longer necessary, and we will remove this at some point.
"""
  }

  field publish_audit {
    type:       bool
    default:    false
    write_lock: true
    shortdoc:   "Run Audit Report"
    doc:        """
This controls whether the default 'usage' audit is published. The
usage audit is a pre-configured report called 'audit'.

By default, it is hooked up to a file sink, the location of which is
specified by the audit_location variable, and the max size of which is
specified  by the audit_file_size variable.
"""
  }

  field audit_location {
    type:       string
    default:    "chalk-audit.json"
    shortdoc:   "Audit file location"
    doc:  """
This controls where the default audit log goes, if enabled.  If you enable and set this to "", then you need to provide your own output configuration that subscribes to the 'audit' topic.

If you provide a file name only, the directories in log_search_path are tried in order.  Failing that, it uses /tmp.

If you provide an absolute path, and the log file cannot be opened, then it falls back on the search path (keeping the file name oprtion).

Defaults to 'chalk-audit.json'
"""
  }

  field audit_file_size {
    type:       Size
    shortdoc:   "Audit Report log max size"
    default:    <<100mb>>
    doc:        """
When using the default log file for the built-in audit report (which, by the way, is off by default), this controls the maximum size allowable for the audit log. If a write to the cache would exceed this amount, the system will truncate down to 75% of the size.
"""
  }

  field log_search_path {
    type:    list[string]
    default: ["/var/log/chalk/", "~/.log/chalk/", "."]
    shortdoc: "Log file location search path"
    doc: """
Any time you open a log file (for instance, with the output sink configurations, or with the builtin (optional) audit log, relative paths attempt to open a log fle, checking each one of these locations until one succeeds (making any directories necessary).

This path is also searched if there is a problem writing log files where an explicit path is given.

Note that if nothing in this path works, Chalk tries to create a temporary directory for log files, just for that invocation.
"""
  }

  field artifact_search_path {
    type:     list[string]
    default:  ["."]
    shortdoc: "Search Path"
    doc:      """
Set the default path to search for artifacts, unless overriden by command-line arguments.
"""
  }

  field always_try_to_sign {
    type:     bool
    default:  true
    shortdoc: "Always sign"
    doc:      """
When true, Chalk will attempt to use Cosign to sign *all* artifacts
when chalking. If it's false, Chalk will still try to sign when
chalking containers, as otherwise it's not practical to determine when
containers have been modified since chalking.

Even if this is false, Chalk will try to sign if either the chalk
profile or the artifact reporting profile have SIGNATURE set.
"""    
  }

  field use_transparency_log {
    type:     bool
    default:  false
    shortdoc: "Use transparency logging"
    doc: """
When this is true, digital signings will get published to a transparency log, and extracts from container images will attempt to validate in the transparency log.

"""    
  }

  field use_internal_password {
    type:     bool
    default:  false
    shortdoc: "Embed signing password"
    doc: """
When this is true, then Chalk will look inside the chalk mark for the
signing password when needed (and decrypt it from an embedded
key). When this is false, Chalk instead uses the `CHALK_PASSWORD`
environment variable to read the password.

Generally, our recommendation is for this value to be `false` and to
use a secret manager to load the environment variable right before
calling chalk (make sure it gets unloaded immediately after).

However, this option is provided for those who wish to hardcode
secrets; this manages the hardcoding, and even encrypts it with a key
specific to the binary. If you compile the binary yourself, and care
about operational security of the binary (making sure, for instance,
it's only ever readable by the current user when running it), then
this is a plausable approach.

For the `chalk setup` command, this will cause the embedding to
happen. For any other command, when the password is needed, it will
cause Chalk to look for the internal password first, and then try the
environment variable if that fails.

Otherwise, if this is false, Chalk will not save the password on
`setup`, and for other commands will ONLY check the environment
variable.
"""    
  }

  field signing_key_location {
  type:     string
  default:  "./chalk.key"
  shortdoc: "Signing key location"
  doc: """

This is only used for the `chalk setup` command; it dictates where to
either find a key pair to load, or where to write a keypair being
generated.

Chalk will also embed the keypairs internally, for future operations.
"""
}

  field ignore_patterns {
    type:     list[string]
    default:  [".*/**", "*.txt", "*.json"]
    shortdoc: "Ignore Patterns"
    doc:       """
For operations that insert or remove chalk marks, this is a list of
regular expressions for files to ignore when scanning for artifacts to
chalk.

The 'extract' operation ignores this.
"""
  }

  field load_external_config {
    type:     bool
    default:  true
    shortdoc: "Run any external configuration file, if found"
    doc: """
Turn this off to prevent accidentally picking up an external configuration file. You can always re-enable at the command line with --yes-external-config
"""
  }

  field load_embedded_config {
    type:     bool
    default:  true
    shortdoc: "Run the embedded configuration file"
    doc: """
This variable controls whether the embedded configuration file runs. Obviously, setting this from within the embedded configuration file is pointless, as it's used before then. But, you can set this with --no-use-embedded-config at the command line.

This is primarily meant to make it easier to test new configurations by disabling the embedded config and only running the external (candidate) config.
"""
  }

  field inform_if_cant_sign {
    type: bool
    default: false
    shortdoc: "Inform if we can't sign"
    doc: """
If true, when signing is on, but Chalk cannot find a GPG passphrase in
its environment, this will cause an info-level message to be logged.
"""
  }

  field run_sbom_tools {
    type:     bool
    default:  false
    shortdoc: "Run any configured SBOM tools"
    doc: """
When true, this will cause chalk to run any configured and enabled SBOM tool implementations. Currently, this is just syft, which will be downloaded into /tmp if not found on the system.

You can change that directory by setting the global variable SYFT_EXE_DIR with the := operator (it is *not* an attribute).

The syft command line arguments used at invocation (minus the target location) can be set via the SYFT_ARGV global variable.  It's default value is:

-o cyclonedx-json 2>/dev/null
"""
  }

  field run_sast_tools {
    type:     bool
    default:  false
    shortdoc: "Run any configured SAST tools"
    doc: """
When true, this will cause chalk to run any configured static analysis security testing (SAST) tools.  This is off by default, since it could add a noticable delay to build time for large code bases.

Currently, the only available tool out of the box is semgrep, and will only work on machines that either already have semgrep installed, or have Python3 installed.
"""
  }

  field recursive {
    type:     bool
    default:  true
    shortdoc: "Recursive"
    doc:      """
When scanning for artifacts, if this is true, directories in the
artifact search path will be traversed recursively.
"""
  }

  field docker_exe {
    type:     string
    require:  false
    shortdoc: "Docker command location"
    doc: """
When running the 'docker' command, this tells chalk where to look for the docker executable to exec.

If this is not provided, or if the file is not found, chalk will search the PATH for the first instance of 'docker' that is not itself (We generally expect renaming chalk to docker and using this variable to point to the actual docker EXE will be the most seamless approach).

Note that, when chalk is invoked with 'docker' as its EXE name, the default IO configuration is to *NOT* anything chalk-specific on the console.
"""
  }

  field chalk_contained_items {
    type:    bool
    default: false
    shortdoc: "Add chalk to embedded chalkable objects"
    doc: """
When chalking an artifact that can itself contain artifacts, this field dictates whether the contents should be chalked, or if just the outer artifact.  This also controls whether, on extraction, chalk will report contents.

Currently, this is only fully respected for artifacts in ZIP format (e.g., JAR files)

When this is true, docker builds will chalk items in any local context directories. Remote contexts currently do not get chalked when this is true.
"""
  }

  field publish_defaults {
    type:       bool
    default:    false
    write_lock: true
    shortdoc:   "Publish Defaults"
    doc:        """
When set to true, configuration information will be published to the
"defaults" topic, which, by default, will print to stderr.

This is similar to the 'chalk defaults' command, except that it causes
the same type of information to be added at the end of *any*
operation.

This is useful when you have conditional logic in your configuration
file, and want to see the results of config file evaluation for
specific sets of command-line arguments.
"""
  }

  field ktype_names {
    type:       list[string]
    default:    key_types
    write_lock: true
    hidden:     true
    doc:        "Internal; used to map key type enum values back to text."
  }

  field defaults_disclaimer {
    type:       string
    hidden:     true
    doc:        "Externalize disclaimer string."
    write_lock: true
    default:  """
Note that these values can change based on logic in the config file.  You can cause the current configuration to be published to the 'defaults' topic on any run by setting 'publish_defaults' in the con4m configuration or passing '--publish-defaults' on the command line.

Note that '--no-publish-defaults' at the command line will block this feature, even if the configuration file asks for it to be used. Running the 'defaults' command always publishes, though.
"""
  }
  field use_report_cache {
    type:       bool
    default:    true
    shortdoc:   "Report cache on"
    doc:       """
The report cache is a localfile in JSON format that stores any reports that don't reach their destination. This will get used any time publishing to *any* sink fails to write.

The report cache will re-publish on subsequent runs by appending any unsent messages to the json report (this is why reports are an array).  It does so on a sink-by-sink basis, based on the name of the sink.  It will never publish to the same sink twice.

A few important notes:

1. This functionality applies both to the default 'report' topic, and for custom reports.

2. If the report cache successfully flushes all its contents, it will leave a zero-byte file (it does not remove the file).  Still, it doesn't write the file for the first time until there is a failure.

3. If, for any reason, writing to the report cache fails, there will be a forced write to stderr, whether you've subscribed to it or not, in an attempt to prevent data loss.

4. There is currently not a way to specify a 'fallback' sink.

5. If this is off, there is no check for previously cached data.

Note that this field is set on the command line with --use-report-cache / --no-use-report-cache.
"""
  }

  field report_cache_location {
    type:       string
    default:    "./chalk-reports.jsonl"
    shortdoc:   "Report cache location"
    doc:        """
Where to write the report cache, if in use.  Note that Chalk does not try to write this where log files go, since it is not really a log file.  It only tries to write to the one configured location, and failing that will try a tmp file or writing to the user (see the docs for use_report_cache).
"""
  }

  field report_cache_lock_timeout_sec {
    type:    int
    default: 15
    shortdoc: "Report cache lock acquisition timeout"
    doc: """
When using the report cache, it's possible multiple parallel instances
of chalk on the same machine will be attempting to use the same cache
file.

For cases when this happens, Chalk uses a file locking system. If
another running process holds the lock, chalk will keep retrying once
per second for the number of specified seconds, before giving up
(stale lock files are ignored).

This variable then controls how many retries will be made, and thus
the approximate maximum delay to the start of work.

If you're running tools via chalk that can take a while to run, then
you probably want to bump this number up, or use multiple report
caches, or somesuch.

If you have more typical build runs that complete quickly, then this
number can stay pretty low.
"""
  }

  field force_output_on_reporting_fails {
    type:       bool
    default:    true
    shortdoc:  "Force stderr reporting on io error"
    doc: """
If this is true, and no reporting configurations successfully handle the metadata, then this will cause the report that should have been output to write to the user's terminal if there is one, or stderr if not.

Note that this is NOT checked if there is a report cache enabled; even if the report cache fails, then there will be console output.
"""
  }

  field env_always_show {
    type:       list[string]
    default:    ["PATH", "PWD", "XDG_SESSION_TYPE", "USER", "SSH_TTY"]
    shortdoc:   "Env Vars to show full data for"
    doc:        """
For the INJECTOR_ENV and _ENV metadata keys, any environment variable listed here will get reported with its actual value at the time the chalk command is invoked.
"""
  }

  field env_never_show {
    type:       list[string]
    default:    []
    shortdoc:   "Env Vars to ignore"
    doc:        """
For the INJECTOR_ENV and _ENV metadata keys, any environment variable listed here will get ignored.
"""
  }

  field env_redact {
    type:       list[string]
    default:    ["AWS_SECRET_ACCESS_KEY"]
    shortdoc:   "Env Vars to redact"
    doc:        """
For the INJECTOR_ENV and _ENV metadata keys, any environment variable listed here will get redacted for privacy.  Currently, that means we give the value <<redacted>>; we do not try to detect sensitive data and redact it.
"""
  }

  field env_default_action {
    type:     string
    choice:   ["show", "redact", "ignore"]
    default:  "ignore"
    shortdoc: "Default envvar action"
    doc:        """
For the INJECTOR_ENV and _ENV metadata keys, any environment variable that is not listed explicitly in the above lists will be handled as specified here.
"""
  }

  field validate_configs_on_load {
    type:        bool
    default:     true
    hidden:      true
    doc:         """
Suppress validation of configuration files on loading.  Please don't do this!
"""
  }

  field validation_warning {
    type:        bool
    default:     true
    shortdoc: "Show 'chalk load' validation warning"
    doc:         """
Show the (admittedly verbose) warning you get when running 'chalk load'.
"""
  }

  field keys_that_can_lift {
    type:    list[string]
    default: ["SBOM", "SAST"]
    validator: func liftable_key_check
    shortdoc: "Specify which chalk keys *can* be lifted."
    doc: """
Normally, at chalk time, chalkable artifact keys can only appear in
the artifact report, even if it's the same info across all artifacts
being chalked at once. You will get an error if trying to add them to
the host report.

However, some items like SBOMs and SAST scan results can be huge, and
the duplication not awesome.

Such keys must be itemized here, but you get 3 choices:

1. Leave the key in the artifact report and accept the spam.

2. Put the key in the host report but NOT the artifact report; if all
artifacts have the same value, it'll be reported at the host level a
single time. However, if it's not the same across all chalked
artifacts, it gets DROPPED.

3. Put the key in BOTH places. If you do that, it'll report at the
host level if all values are the same, and at the artifact level if
not.
"""

  }

  field skip_command_report {
    type:        bool
    default:     false
    shortdoc: "Skip the command report"
    doc: """
Skip publishing the command report (i.e., the PRIMARY report). NO output sinks will get it.

For most commands, this defeats the purpose of Chalk, so use it sparingly.

Note that this doesn't turn off any custom reports; you have to disable those seprately.
"""
  }

  field crashoverride_usage_reporting_url {
    type:       string
    default:    "https://chalk.crashoverride.run/v0.1/usage"
    hidden:     true
    doc:        "Used to approximate overall chalk usage. See the usage report"
  }

  field crashoverride_workspace_id {
    type:       string
    default:    "470f1ff7-8b26-43a5-a31d-45c2fcecfaa2"
    hidden:     true
    doc:        "The default value is the one used for anonymous users."
  }
}

func keyspec_exists(name) {
  if sections("keyspec").contains(name) { return true; }
  return false
}

func validate_probability(name, value) {
  if value <= 0 or value > 100 {
    return "Probability must be an int greater than 0, but less than or equal to 100"
  }
  return ""
}

func key_callback_check(keyname, callback: func (string) -> `x) {
  path      := split(keyname, ".")
  key_name  := path[1]
  fieldType := $(attr_get("keyspec." + key_name + ".type", typespec))
  expected  := to_type("(string) -> " + fieldType)
  actual    := typeof(callback)

  if not typecmp(expected, actual) {
    return ("In: '" + keyname + "' callback is of type '" + $(actual) +
            "', but the key specification requires the type: '" +
  	    $(expected) + "'")
  }

  return ""
}

func never_early_check(keyname, val) {
  result := ""

  if val == true {
    path       := split(keyname, ".")
    kind_field := "keyspec." + path[1] + ".kind"
    kind       := attr_get(kind_field, int)

    if kind != ChalkTimeArtifact {
      return "'never_early' only for fields of type ChalkTimeArtifact"
    }
  }
}

func plugin_keyspec_check(keyname, val: list[string], context) {
  result := "" # Default on success

  # For each key in val...
  # 1) If the key doesn't exist, fail.
  # 2) If the key exists, it must be either of kind ChalkTimeHost or
  #    ChalkTimeArtifact
  # 3) If it's of type chalk, never_early must be false.

  for i from 0 to len(val) {
    item := val[i]

    if item == "*" { continue; }

    if not keyspec_exists(item) {
      return (keyname + ": specified key '" + item + "' does not have an " +
        "associated keyspec")
    }

    base              := "keyspec." + item + "."
    kind_field        := base + "kind"
    kind              := attr_get(kind_field, int)

    if context == CCPreRun {
      if kind == ChalkTimeHost { continue }
      elif kind == ChalkTimeArtifact {
        never_early_field := base + "never_early"
        if attr_get(never_early_field, bool) == false {
  	  continue
	}
      }
      return (keyname + ": specified key '" + item + "' cannot appear in " +
             "the 'Pre-Run' collection context")
    }
    elif context == CCArtifact or context == CCPostChalk {
      if kind == RunTimeHost or (kind == ChalkTimeHost and context == CCPostChalk) {
        return (keyname + ": specified key '" + item + "' is a host-level " +
	        "key that cannot appear at artifact collection time")
      }
      if context == CCPostChalk and kind == ChalkTimeArtifact {
        return (keyname + ": specified key '" + item + "' must be available " +
	       "during artifact collection")
      }
    }
    else {  # context == CCPostRun
      if kind == RunTimeHost { continue }

      return (keyname + ": specified key '" + item + "' cannot appear in " +
              " the 'Post-Run' collection context")
    }
  }
}

func pre_run_key_check(keyname, val) {
  return plugin_keyspec_check(keyname, val, CCPreRun)
}

func chalk_key_check(keyname, val) {
  return plugin_keyspec_check(keyname, val, CCArtifact)
}

func post_chalk_key_check(keyname, val) {
  return plugin_keyspec_check(keyname, val, CCPostChalk)
}

func post_run_key_check(keyname, val) {
  return plugin_keyspec_check(keyname, val, CCPostRun)
}

func override_key_check(keyname: string, val: list[string]) {
  result := ""
  parts := keyname.split(".")
  base  := "plugin." + parts[1] + "."
  k1    := attr_get(base + "pre_run_keys",    list[string])
  k2    := attr_get(base + "artifact_keys",   list[string])
  k3    := attr_get(base + "post_chalk_keys", list[string])
  k4    := attr_get(base + "post_run_keys",   list[string])

  for i from 0 to len(val) {
    if k1.contains(val[i]) or k1.contains("*") { continue; }
    if k2.contains(val[i]) or k2.contains("*") { continue; }
    if k3.contains(val[i]) or k3.contains("*") { continue; }
    if k4.contains(val[i]) or k4.contains("*") { continue; }
      return (keyname + ": Plugin does not produce the metadata key: '" +
             val[i] + "'" )

  }
}

func liftable_key_check(keyname, val: list[string]) {
  result := ""
  
  for i from 0 to len(val) {
    item := val[i]
    
    if not keyspec_exists(item) {
      return (keyname + ": key '" + item + " is specified to be liftable, " +
      "but no such key has been defined.")
    }

    base       := "keyspec." + item + "."
    kind_field := base + "kind"
    kind       := attr_get(kind_field, int)

    if kind != ChalkTimeArtifact {
      return (keyname + ": specified key '" + item + "' is not liftable " +
      "because it is not a chalkable artifact key.")
    }
  }
}

func pc_err(profile, key, specified, err) {
  if specified {
      return ("Profile '" + profile + "' specifies reporting key '" + key +
           "', but " + err)
  }

  return ("Profile '" + profile + "' does not specify reporting key '" + key +
           "', but " + err)
}

func profile_check_base(profile_name, profile_type, cmd) {
  result := ""
  sects  := sections("profile")

  if profile_name == "" {
    if profile_type == PTChalk and all_cmds_that_insert.contains(cmd) {
      return ("outconf configuration for command '" + cmd + "' must provide " +
      "a valid profile for chalking.")
    }
    return
  }
  if not sects.contains(profile_name) {
    return "there is no defined profile named '" + profile_name + "'"
  }

  specs         := sections("keyspec")
  key_attr_path := "profile." + profile_name + ".key"
  profile_keys  := sections(key_attr_path)

  for i from 0 to len(profile_keys) {
    if not specs.contains(profile_keys[i]) {
        return ("profile '" + profile_name + "' contains a key: '" +
                profile_keys[i] + "', which has no associated keyspec.")
    }
  }
  for i from 0 to len(specs) {
    key_name   := specs[i]
    spec_base  := "keyspec." + key_name
    key_kind   := attr_get(spec_base + ".kind", int)

    if profile_type == PTChalk {
        if key_kind == RunTimeArtifact or key_kind == RunTimeHost { continue }
        
        flag := false
        
        if attr_get(spec_base + ".required_in_chalk_mark", bool) {
          flag := true
        }
        if cmd == "load" and attr_get(spec_base + ".required_in_self_mark",
                                       bool) {
          flag := true
        }
        if flag {
          add_override(key_attr_path + "." + key_name + ".report", true)
        }
      continue
    }

    if not profile_keys.contains(key_name) { continue }

    keyconfbase := "profile." + profile_name + ".key." + key_name + "."

    if attr_get(keyconfbase + "report", bool) == false { continue }
    
    
    # By here, we know this profile wants to set this key explicitly,
    # and that we are not in a chalk profile.
    #
    # - ChalkTimeHost keys can appear anywhere.
    # - ChalkTimeArtifact keys can appear in per-artifact reports,
    #   and in host-reports as long as the keyspec set never_early to 'false'
    #   *and* the key is in the `keys_that_can_lift` field. Otherwise,
    #   it can only appear in an artifact report.
    
    # - RunTimeArtifact keys can appear in per-artifact reports only.
    # - RunTimeHost keys can appear in host reports only.
    #
    # If the profile type is PTChalkTimeArtifact, we don't allow RunTimeArtifact
    # or RunTimeHost keys.

    valid_lifts := attr_get("keys_that_can_lift", list[string])

    if profile_type == PTArtifact or profile_type == PTChalkTimeArtifact {
      if key_kind == RunTimeHost {
        return pc_err(profile_name, key_name, true,
                      "that key cannot appear in artifact report spec")
      }
      if key_kind == RunTimeArtifact and profile_type == PTChalkTimeArtifact {
        return pc_err(profile_name, key_name, true,
        "This report is used at build time, so keys collected post-chalk " +
        "aren't allowed.")
      }
      continue
    }
    # Else, profile type is PTHost
    if key_kind == RunTimeArtifact {
       return pc_err(profile_name, key_name, true,
          "non-chalkable artifact info can't be in a host-level report spec")
    }
    elif key_kind == ChalkTimeArtifact {
      if attr_get("keyspec." + key_name + ".never_early", bool) == true {
        return pc_err(profile_name, key_name, true,
        "that key is artifact specific, so can't be in host-level report spec")
      }
      if valid_lifts.contains(key_name) {
        continue
      }
      return pc_err(profile_name, key_name, true,
      "That key is not configured to be liftable.")
    }
    # Otherwise, all is good in the cosmos.
  }
}

func in_outconf(name) {
  secname := name.split(".")[1]
  return "For output configuration of command '" + secname + "': "
}

func in_report(name) {
  reportname := name.split(".")[1]
  return "In custom report '" + reportname + "': "
}

func outconf_chalk_check(name, profile_name) {
  if profile_name == "" { return ""; }
  result := ""
  path   := split(name, ".")
  cmd    := path[1]

  if not contains(all_cmds_that_insert, cmd) {
    return (in_outconf(name) + "' Cannot have a chalk profile; " +
            "It's only valid for commands that add chalk marks.")
  }

  result := profile_check_base(profile_name, PTChalk, cmd)
  if result != "" {
    result := in_outconf(name) + result
  }
}

func outconf_artifact_check(name, profile_name) {
  if profile_name == "" {
    return ""
  }
  result := profile_check_base(profile_name, PTArtifact, "")
  if result != "" {
    result := in_outconf(name) + result
  }
}

func outconf_host_check(name, profile_name) {
  if profile_name == "" {
    return ""
  }
  result := profile_check_base(profile_name, PTHost, "")
  if result != "" {
    result := in_outconf(name) + result
  }
}

func outconf_invalid_chalk_check(name, profile_name) {
  result := ""
  path   := split(name, ".")
  cmd    := path[1]

  if profile_name == "" {
    return ""
  }

 if contains(all_cmds_that_insert, cmd) {
    return (in_outconf(cmd) + "' Cannot have an invalid chalk profile; " +
            "It's only valid for commands that do NOT add chalk marks.")
  }

  result := profile_check_base(profile_name, PTArtifact, "")
  if result != "" {
    result := in_outconf(name) + result
  }
}

func custom_report_artifact_check(name, profile_name) {
  result := profile_check_base(profile_name, PTArtifact, "")
  if result != "" {
    result := in_report(name) + result
  }
}

func label_profile_check(name, profile_name) {
  if profile_name == "" {
    return ""
  }
  result := profile_check_base(profile_name, PTChalkTimeArtifact, "")
  if result != "" {
    result := in_report(name) + result
  }
}

func is_valid_label(label) {
  result := true
  chars := to_chars(label)
  l     := chars.len()
  for i from 0 to l {
    c := chars[i]
    if is_alphanum(c) {
      continue
    }
    if contains(['.', '-', '$'], c) {
      continue
    }
    return false
  }
}

func label_prefix_check(name, value) {

  if value.is_valid_label() {
    return ""
  } else {
    return ("Docker label prefix must only contain letters, numbers, " +
            "'.' or '-' (when processing label '" + value + "'")
  }
}

func custom_labels_check(name, value) {
  result := ""
  stuff := value.keys()
  l     := len(stuff)
  for i from 0 to l {
    if not is_valid_label(stuff[i]) {
      return ("Docker label prefix must only contain letters, numbers, " +
              "'.' or '-' (when processing label '" + stuff[i] + "'")
    }
  }
}

func exec_arg_semantics_check(name, value) {
  result := ""
  if value and attr_get("exec.append_command_line_args", bool) {
    return ("Cannot have both exec.append_command_line_args = true and " +
            "exec.override_ok = true")
  }
}

func sink_ref_check(name, sink_config_name) {
  result := ""

  # No sink config means use the default crashoveride one.
  if sink_config_name == "" { return; }
  if not sections("sink_config").contains(sink_config_name) {
    return "No sink configuration named: '" + sink_config_name + "'"
  }
}

func use_when_check(name, value: list[string]) {
  result := ""

  if value.contains("*") {
    if value.len() > 1 {
      return "For field use_when, '*' should be the only item when it appears"
    }
    return
  }
  for i from 0 to value.len() {
    if valid_chalk_cmds.contains(value[i]) {
      continue
    }
    if other_report_ops.contains(value[i]) {
      continue
    }
    return ("'use_when' must be a valid chalk report type, or a '*' " +
           " to indicate all of them. '" + value[i] +
	   "' isn't a chalk command.  Valid report types are: " +
	   valid_chalk_cmds.join(", ") + ", " + other_report_ops.join(", ")
	   )
  }
}

func custom_report_host_check(name, profile_name) {
  result := profile_check_base(profile_name, PTHost, "")
  if result != "" {
    result := in_report(name) + result
  }
}

func sink_check(name, scfg: string) {
  result := ""
  if not sections("sink_config").contains(scfg) {
    report := name.split(".")[1]

    return ("The report '" + report + "' applies sink configuration '" + scfg +
           "', but that configuration has not been set.")
  }
}

func sink_list_check(name, sinklist: list[string]) {
  result := ""
  for i from 0 to len(sinklist) {
     result := sink_check(name, sinklist[i])
     if result != "" { return; }
  }
}

func sink_filter_check(name, filterList: list[string]) {
  result := ""
  for i from 0 to len(filterList) {
    if not known_sink_filters.contains(filterList[i]) {
      return "Unknown filter in sink configuration: " + filterList[i]
    }
  }
}

# TODO: should add a "choices" constraint to con4m.
func zip_check(keyname: string, value: list[string]) {
  valid_items := ["zip", "jar", "war", "ear"]

  for i from 0 to len(value) {
    if not contains(valid_items, value[i]) {
      return "'" + value[i] + "' is not a supported zip-based file extension."
    }
  }
  return ""
}

func py_check(keyname: string, value: list[string]) {
  valid_items := ["py", "pyw", "ipy"]

  for i from 0 to len(value) {
    if not contains(valid_items, value[i]) {
      return "'" + value[i] + "' is not a supported python source file extension."
    }
  }
  return ""
}

func pyc_check(keyname: string, value: list[string]) {
  valid_items := ["pyc", "pyo", "pyd"]

  for i from 0 to len(value) {
    if not contains(valid_items, value[i]) {
      return "'" + value[i] + "' is not a supported python bytecode file extension."
    }
  }
  return ""
}

func default_command_check(keyname, value) {
  value := value.split(".")[0]
  if contains(valid_chalk_cmds, value) {
    return ""
  }
  return ("The attribute 'default_command' is set to '" + value +
          "', which is not a valid chalk command. Must be one of: " +
	  join(valid_chalk_cmds, ", "))
}

# Run any checks across fields that we haven't yet done...
func custom_report_extra_validation() {
  result       := ""
  report_sects := sections("custom_report")
  for i from 0 to len(report_sects) {
    base := "custom_report." + report_sects[i] + "."
    s1   := attr_get(base + "artifact_report", string)
    s2   := attr_get(base + "host_report", string)
    if s1 == "" and s2 == "" {
      return "Custom Report '" + report_sects[i] + "' must set a valid profile"
    }
  }
}

func key_name_validation() {
  result     := ""
  spec_sects := sections("keyspec")
  for i from 0 to len(spec_sects) {
    key_name := spec_sects[i]
    base     := "keyspec." + key_name + "."
    if attr_get(base + "standard", bool) { continue; }
    kind     := attr_get(base + "kind", int)
    if kind == ChalkTimeHost or kind == ChalkTimeArtifact {
      if key_name.find("X-") == 0 { continue; }
    }
    elif key_name.find("_X-") == 0 { continue; }
    return ("Custom key '" + key_name + "' is invalid. Chalkable custom " +
            "keys must start with X- (or _X- for non-chalkable keys)")
  }
}

func sink_object_check(path) {
  result := ""
  f := fields(path)

  for i from 0 to len(f) {
    fieldname := path + "." + f[i]
    fieldtype := attr_type(fieldname)
    if typecmp(fieldtype, bool) or typecmp(fieldtype, string) {
      continue
    }
    return ("All sink fields must be a bool indicating whether a field is " +
            "required, or a string specifying a default value " +
	    "(offending field: '" + f[i] + "' has type: " + $(fieldtype))
  }
}

sink_config_skip_fields := ["enabled", "loaded", "sink", "filters"]
export sink_config_skip_fields

func sink_config_check(path) {
  result   := ""
  sinkname := attr_get(path + ".sink", string)
  if sinkname == "" {
    return # Unconfigured.
  }
  if not attr_exists("sink." + sinkname) {
    return "No such sink configured: '" + sinkname + "'"
  }
  sinkfields := fields("sink." + sinkname)
  conffields := fields(path)

  for i from 0 to len(conffields) {
    conffield := conffields[i]
    if sink_config_skip_fields.contains(conffield) {
      continue
    }

    if not sinkfields.contains(conffield) {
      return ("sink config provides field '" + conffield +
              "', but the specified sink '" + sinkname +
	      "' does not use that field.")
    }

    if contains(["timeout", "truncation_amount", "max"], conffield) {
      t := attr_type(path + "." + conffield)
      if not typecmp(t, Size) and not typecmp(t, int) {
          return "max: This field must be a con4m Size, or an int (in bytes)"
      }
    }
    elif conffield == "headers" {
      t := attr_type(path + "." + conffield)
      if not typecmp(t, dict[string, string]) {
          return conffield + ": Field must be a dict[string, string]"
      }
    }
    elif contains(["enabled", "use_search_path", "disallow_http"], conffield) {
      t := attr_type(path + "." + conffield)
      if not typecmp(t, bool) {
          return conffield + ": Field must be `true` or `false`"
      }
    }
    elif contains(["log_search_path", "filters"], conffield) {
      t := attr_type(path + "." + conffield)
      if not typecmp(t, list[string]) {
          return conffield + ": Field must be a list[string]"
      }
    }
    elif not typecmp(attr_type(path + "." + conffield), string) {
      return "This field must be a string."
    }
    elif conffield == "pinned_cert_file" {
      if attr_exists(path + ".pinned_cert") {
        return ("Cannot have `pinned_cert_file` and `pinned_cert` in the same" +
        "sink configuration.")
      }
    }
    
  }

  for i from 0 to len(sinkfields) {
    fullname := "sink." + sinkname + "." + sinkfields[i]
     t := attr_type(fullname)
     if not typecmp(t, bool) {   # TODO-- short circuit didn't work??
       continue
     }
     if not attr_get(fullname, bool) {
       continue
     }
     if not conffields.contains(sinkfields[i]) {
       return "sink config is missing required field: '" + sinkfields[i] + "'"
     }
  }
}

func final_check() {
  result := key_name_validation()
  if result != "" { return; }
  result := custom_report_extra_validation()
  if result != "" { return; }
}
